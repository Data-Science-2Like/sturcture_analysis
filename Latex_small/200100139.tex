

\documentclass{article}
\newcommand{\keywords}[1]{\textbf{Keywords:}\quad #1}

\usepackage{longtable}
\usepackage{multirow} \usepackage{booktabs} \usepackage{rotating} \usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{graphicx}
\graphicspath{{images/}}



\usepackage{lmodern} \usepackage{graphicx} \usepackage{subfig} \usepackage{lscape}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	citecolor=blue,
	linkcolor=red,
	filecolor=magenta,      
	urlcolor=blue
}
\usepackage{verbatim} 
\usepackage{authblk}



\title{Handwritten Optical Character Recognition (OCR): A Comprehensive Systematic Literature Review (SLR) }


\author[1,4]{Jamshed Memon \thanks{All authors have contributed equally}}
\author[3]{Maira Sami}
\author[1,2]{Rizwan Ahmed Khan}

\affil[1]{Faculty of IT, Barrett Hodgson University, Karachi, Pakistan.}
\affil[2]{LIRIS, Universit\'e Claude Bernard Lyon1, France.}
\affil[3]{CIS, NED University of Engineering and technology, Karachi, Pakistan.}
\affil[4]{School of Computing, Quest International University, Perak, Malaysia.}
\date{}















\begin{document}
\maketitle










\begin{abstract}

Given the ubiquity of handwritten documents in human transactions, Optical Character Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data. During last decade, researchers have used artificial intelligence / machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format. The objective of this review paper is to summarize research that has been conducted on character recognition of handwritten documents and to provide research directions. In this Systematic Literature Review (SLR) we collected, synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics) which were published between year 2000 to 2018. We followed widely used electronic databases by following pre-defined review protocol. Articles were searched using keywords, forward reference searching and backward reference searching in order to search all the articles related to the topic. After carefully following study selection process 142 articles were selected for this SLR. This review article serves the purpose of presenting state of the art results and techniques on OCR and also provide research directions by highlighting research gaps.  





\keywords {Optical character recognition, classification, languages, feature extraction, deep learning}

\end{abstract}




\section{Introduction}
Optical character recognition (OCR) is a system that converts the input text into machine encoded format \cite{Tappert}. Today, OCR is helping not only in digitizing the handwritten medieval manuscripts \cite{Kumar2018}, but also helping in converting the typewritten documents into digital form \cite{Radwan2018}. This has made the retrieval of the required information easier as one doesn’t have to go through the piles of documents and files to search the required information. Organizations are satisfying the needs of digital preservation of historic data \cite{HistMed}, law documents \cite{Ashley2010}, educational persistence \cite{Zanibbi2012} etc. 

An OCR system depends mainly, on the extraction of features and discrimination / classification of these features (based on patterns). Handwritten OCR have received increasing attention as a subfield of OCR.  It is further categorized into offline system \cite{pathan2012recognition,parvez2013offline} and online system \cite{connell2001template} based on input data. The offline system is a static system in which input data is in the form of scanned images while in online systems nature of input is more dynamic and is based on the movement of pen tip having certain velocity, projection angle, position and locus point. Therefore, online system is considered more complex and advance, as it resolves overlapping problem of input data that is present in the offline system.

One of the earliest OCR system was developed in 1940s, with the advancement in the technology over the time, the system became more robust to deal with both printed and handwritten characters and this led to the commercial availability of the OCR machines. In 1965, advance reading machine ``IBM 1287'' was introduced at the ``world fair'' in New York \cite{Mori1992}. This was the first ever optical reader, which was capable of reading handwritten numbers.  During 1970s,  researchers focused on the improvement of response time and performance of the OCR system.  

The next two decades from 1980 till 2000, software system of OCR was developed and deployed in educational institutes, census OCR \cite{wilkinson1992first} and for recognition of stamped characters on metallic bar \cite{Kovacs-V1995}. In early 2000s, binarization techniques were introduced to preserve historical documents in digital form and provide researchers the access to these documents \cite{wolf2002text,gatos2004adaptive,he2005comparison,sari2002off}. Some of the challenges of binarization of historical documents was the use of nonstandard fonts, printing noise and spacing. In mid of 2000 multiple applications were introduced that were helpful for differently abled people. These applications helped these people in developing reading and writing skills. 


In the current decade, researchers have worked on different machine learning approaches which include Support Vector Machine (SVM), Random Forests (RF), $k$ Nearest Neighbor ($k$NN), Decision Tree (DT) \cite{Mitchell, lorigo2006offline, Khan2019a} etc. Researchers combined these machine learning techniques with image processing techniques to increase accuracy of optical character recognition system. Recently researchers has focused on developing techniques for the digitization of handwritten documents, primarily based on deep learning \cite{DL} approach. This paradigm shift has been sparked due to adaption of cluster computing and GPUs and better performance by deep learning architectures \cite{66287}, which includes Recurrent Neural Networks (RNN), Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM) networks etc. 


This Systematic Literature Review (SLR) will not only serve the purpose of presenting literature in the domain of OCR for different languages but will also highlight research directions for new researcher by highlighting weak areas of current OCR systems that needs further investigation. 

This article is organized as follows. Section \ref{RM} discusses review methodology employed in this article. Review methodology section includes review protocol, inclusion and exclusion criteria, search strategy, selection process, quality assessment criteria and meta data synthesis of selected studies. Statistical data from selected studies is presented in Section \ref{SR}. Section \ref{RQ} presents research question and their motivation. Section \ref{classi} will discuss different classifications methods which are used for handwritten OCR. The section will also elaborate on structural and statistical models for optical character recognition. Section \ref{dataset} will present different databases (for specific language) which are available for research purpose. Section \ref{lang} will present research overview of language specific research in OCR, while Section \ref{future} will highlight research trends. Section \ref{conclusion} will summarize this review findings and will also highlight gaps in research that needs attention of research community.





\section{Review methods} \label{RM}


As mentioned above, this Systematic Literature Review (SLR) aims to identify and present literature on OCR by formulating research questions and selecting relevant research studies. Thus, in summary this review was:


\begin {enumerate}

\item	To summarize existing research work (machine learning techniques and databases) on different languages of handwritten character recognition systems.
\item		To highlight research weakness in order to eliminate them through additional research.  
\item		To identify new research areas within the domain of OCR. 
\end {enumerate}


We will follow strategies proposed by Kitchenham et al. \cite{kitchenham2010systematic}. Following proposed strategy, in subsequent sub-sections review protocol, inclusion and exclusion criteria, search strategy process, selection process and data extraction and synthesis processes are discussed. 



\subsection{Review protocol}


Following the philosophy, principles and measures of the Systematic Literature Review (SLR) \cite{kitchenham2010systematic}, this systematic study was initialized with the development of comprehensive review protocol. This protocol identifies review background, search strategy, data extraction, research questions and quality assessment criteria for the selection of study and data analysis. 

The review protocol is what that creates a distinction between an SLR and traditional literature review or narrative review  \cite{kitchenham2010systematic}. It also enhances the consistency of the review and reduces the researchers' biasness. This is due to the fact that researchers have to present search strategy and the criteria for the inclusion of exclusion of any study in the review.




\subsection{Inclusion and exclusion criteria}\label{inc-exc}

Setting up an inclusion and exclusion criteria makes sure that only articles that are relevant to study are included. Our criteria includes research studies from journals, conferences, symposiums and workshops on the optical character recognition of English, Urdu, Arabic, Persian, Indian and Chinese languages. In this SLR, we considered studies that were published from January 2000 to December 2018. 

Our initial search based on the keywords only, resulted in 954 research articles related to handwritten OCRs of different languages (refer Figure \ref{fig:figure1} for compete overview of selection process). After thorough review of the articles we excluded the articles that were not clearly related to a handwritten OCR, but appeared in the search, because of keyword match. Additionally, articles were also excluded based on duplicity, non-availability of full text and whether the studies were related to any of our research questions.

\begin{comment}
\begin{itemize}
\item Full text
\item Published between January 2000 and December 2018
\item They were written in English , Urdu, Indian Script ,Chinese , Farsi and Arabic  
\item Their number of citations 
\item Having different classification schemes of hand written OCRs.
\item Popular data sets 
\item Challenges in current OCRs.
\end{itemize}

Excluded articles on basis of:
\begin{itemize}
\item Their full text not available
\item The material was not related to our research questions 
\item Presence of duplicate study 
\end{itemize}

\end{comment}



\subsection{Search strategy}


\begin{figure*} [!htb]
	\centering
		\includegraphics [scale=0.85]{figure1.pdf}
	\caption{Compete overview of studies selection process}
	\label{fig:figure1}
\end{figure*}



Search strategy comprises of automatic and manual search, as shown in Figure \ref{fig:figure1}. An automatic search helped in identifying primary studies and to achieve a broader perspective. Therefore, we extended the review by inclusion of additional studies. As recommended by Kitchenham et al. \cite{kitchenham2010systematic}, manual search strategy was applied on the references of the studies that are identified after application of automatic search. 

For automatic search, we used standard databases which contain the most relevant research articles. These databases include IEEE Explore, ISI Web of Knowledge, Scopus—Elsevier and Springer. While there is plenty of literature available in magazine, working papers, news papers, books and blogs, we did not choose them for this review article as concepts discussed in these sources are not subjected to review process, thus their quality can't be reliably verified. 

General keywords derived from our research questions and title of study were used to search research articles. Our aim was to identify as many relevant articles as possible from main set of keywords. All possible permutations of Optical character recognition concepts were tried in the search, such as ``optical character recognition'', ``pattern recognition and  OCR'', ``pattern matching and OCR'' etc. 

Once the primary data was obtained by using search strings, data analysis phase of the obtained research papers began with the intention of considering their relevance to research questions and inclusion and exclusion criteria of study. After that, a bibliography management tool i.e. Mendeley was used for storing all related research articles to be used for referencing purpose.  Mendeley also helped us in identifying duplicate studies, because a research paper can be found in multiple databases. 

Manual search was performed with automatic search to make sure that we had not missed anything. This was achieved through forward and backward referencing. Furthermore, for data extraction all the results were imported into spreadsheet. Snowballing, which is an iterative process in which references of references are verified to identify more relevant literature, was applied on primary studies in order to extract more relevant primary studies. Set of primary studies post snowball process was then added to Mendeley. 





\subsection{Study selection process} \label{SSP}


\begin{figure}[!htb]
\centering 
	\includegraphics [scale=1]{distri.pdf}
	\caption{Distribution of sources / databases of selected studies after applying selection process}
	\label{fig:figure 2}
\end{figure}



A tollgate approach was adopted for the selection of the study \cite{nidhra2013knowledge}. Therefore, after searching keywords in all relevant databases, we extracted 954 research studies through automatic search. Majority of these 954 studies, 512 were duplicate studies and were eliminated. Inclusion and exclusion criteria based upon title, abstracts, keywords and the type of publication was applied on the remaining 442 studies. This resulted in exclusion of 230 studies and leaving 212 studies. In the next stage, the selection criteria was applied, thus further 89 studies were excluded and we were left with 123 studies.




Once we finished automatic search stage, we started manual search procedure to guarantee exhaustiveness of the search results.  We performed screening of remaining 123 studies and went through the references to check relevant research articles that could have been left search during automatic search. Manual search added 43 further studies. After adding these studies, pre-final list of 166 primary studies was obtained. 


Next and final stage was to apply the quality assessment criteria (QAC) on pre-final list of 166 studies. Quality assessment criteria was applied at the end as this is the final step through which final list of studies for SLR was deduced. QAC usually identifies studies who's quality is not helpful in answering research question. After applying QAC, 24 studies were excluded and we were left with 142 primary studies. Refer Figure \ref{fig:figure1} for compete step-by-step overview of selection process. 


Table \ref{Tab: Table 1} shows the distribution of the primary / selected studies among various publication sources, before and after applying above mentioned selection process. The same is also shown in Figure \ref{fig:figure 2}. 



\begin{table} [!htb]
\centering

\caption{Distribution of databases of selected studies before and after applying selection process}
\begin{tabular}{ | l | c | c | }    \hline
\textbf{Source} &\textbf{Count before applying } &\textbf{Count after applying} \\
 &\textbf{selection process} &\textbf{selection process}\\ \hline

Elsevier & 207 & 51 \\ \hline
IEEE Xplore & 293& 46 \\ \hline
Springer& 273 & 19 \\ \hline
others & 182 & 26 \\ \hline
Total & 955 & 142 \\ \hline 

\end{tabular}
\label{Tab: Table 1}
\end{table}






\subsection{Quality assessment criteria}


Quality Assessment Criteria (QAC) is based on the principle to make a decision related the overall quality of selected set of studies \cite{kitchenham2010systematic}. Following criteria was used to assess the quality of selected studies. This criterion helped us to identify the strength of inferences and helped us in selecting the most relevant research studies for our research.

Quality Assessment criteria questions:

\begin {enumerate}
\item Are topics presented in research paper relevant to the objectives of this review article?
\item Does research study describes context of the research?
\item Does research article explains approach and methodology of research with clarity?
\item Is data collection procedure explained, If data collection is done in the study?
\item Is process of data analysis explained with proper examples?
\end {enumerate}

We evaluated 166 selected studies by using the above mentioned quality assessment questions in order to determine the credibility of a particular acknowledged study. These five QA schema is inspired by \cite{nidhra2013knowledge}.  The quality of study was measured depending upon the score of each QA question. Each question was assigned 2 marks and the study's quality was considered to be selected if it scored greater than or equal to 5 at the scale of 10. Thus, studies below the score of 5 were not included in the research. Following this criteria, 142 studies were finally selected for this review article (refer Figure \ref{fig:figure1} for compete overview of selection process). 





\subsection{Data extraction and synthesis}
During this phase, meta data of selected studies (142) was extracted. As stated eralier, we used Mendeley and MS Excel to manage meta data of these studies. The main objective of this phase was to record the information that was obtained from the initial studies \cite{kitchenham2010systematic}.  The data containing study ID (to identify each study), study title, authors, publication year, publishing platform (conference proceedings, journals, etc.), citation count, and the study context (techniques used in the study) were extracted and recorded in an excel sheet. This data was extracted after thorough analysis of each study to identify the algorithms and techniques proposed by the researchers. This also helped us to classify the studies according to the languages on which the techniques were applied. Table \ref{Tab:Table 2} shows the fields of the data extracted from research studies.

\begin{table} [!htb]
\centering
\caption{Extracted meta-data fields of selected studies}
	\begin{tabular}{| l | l |}
		\hline
		\textbf{Selected Features}  & \textbf{Description} \\ \hline
		Study identification number				 	& Exclusive identity for selected research article \\ \hline
		Reference														& Bibliographical Reference i.e. Authors, title, publication year etc \\ \hline
		Type of paper												& Journal, conference, workshop, symposium \\ \hline
		Language														& English, Urdu, Chinese, Arabic, Indian, Farsi / Persian \\ \hline
		Citation Count											& Number of Citations \\ \hline
		Technique 													& Feature extraction and classification techniques \\ \hline
		
	\end{tabular}
\label{Tab:Table 2}
\end{table}




\section{Statistical results from selected studies} \label{SR}
In this section, statistical results of the selected studies will be presented with respect to their publication sources, citation count status, temporal view, type of languages and type of research methodologies. 



\subsection{Publication sources overview}

In this review, most of the included studies are published in reputed journals and leading conferences. Therefore, considering the quality of research studies, we believe that this systematic review will be used as a reference to find latest trends and to highlight research directions for further studies in the domain of handwritten OCR. Figure \ref{fig:figure 3} shows the distribution of studies derived from different publication sources. Majority of included studies (87) were published in research journals (61\%), followed by 47 publications in conference articles (33\%). Whereas, few (5) articles were published in workshop proceedings and only 3 relevant articles were found to be presented in symposiums.


\begin{figure}[!tbh]
\centering 
	\includegraphics [scale=0.8]{pubSource.pdf}
	\caption{Study distribution per publication source}
	\label{fig:figure 3}
\end{figure}


\vspace{8mm}
\subsection{Research citations} \label{ResCitation}




\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.7]{citations.pdf}
	\caption{Citation count of selected studies. Numeric value within bar shows number of studies that have been cited $x$ times (corresponding values on the $x$-axis).}
	\label{fig:figure 4}
\end{figure}

Citation count was obtained from Google Scholar. Overall, selected studies have good citation count, which shows that quality of selected studies is worthy to be added in the review and also implies that researchers are actively working in this area of research. As presented in Figure \ref{fig:figure 4}, approximately 95\% of the selected studies have at least one citation, except few paper which are published recently in 2018. Among selected studies, 33 studies have more than 100 citations, 15 studies have been cited between 61-100 times, 25 studies were cited between 33-60 times, 14 studies were cited between 16-30 times and 46 studies were cited between 1 and 15 times. Overall, we predict that selected studies citations will increase further because research articles are constantly being published in this domain. 

Table \ref{Tab:Table 3} provides details of research publications with more than 100 citations each. These articles can be considered to have strong impact on the researchers working to build robust OCR system.




\begin{landscape}
\begin{longtable}{| p{16cm} | p{2cm}| p{1.5cm}| p{1cm}|}
	
	
	
\toprule
	\label{Tab:Table 3}
\textbf{Title of Study}  &\textbf{Citations}& \textbf{Year} &\textbf{ Ref} \\ \hline	

\endhead
\multicolumn{3}{@{}l}{\ldots \textit{continued on next page}}

\endfoot
\endlastfoot


	
Offline handwriting recognition with multidimensional recurrent neural networks.  & 719 & 2009 & \cite{graves2009offline}\\ \hline
Handwritten numeral databases of Indian scripts and multistage recognition of mixed numerals. & 262 & 2009 & \cite{bhattacharya2009handwritten}\\ \hline
A novel connectionist system for unconstrained handwriting recognition. &1175 & 2009 &\cite{graves2009novel}\\ \hline
Markov models for offline handwriting recognition: a survey & 210 & 2009 & \cite{plotz2009markov} \\ \hline
Gujarati handwritten numeral optical character reorganization through neural network. & 148 & 2010 & \cite{desai2010gujarati}\\ \hline
Handwritten character recognition through two-stage foreground sub-sampling. & 112 & 2010 & \cite{vamvakas2010handwritten}\\ \hline
Deep, big, simple neural nets for handwritten digit recognition.  & 784 & 2010 & \cite{cirecsan2010deep}\\ \hline
Diagonal based feature extraction for handwritten character recognition system using neural network. & 175 & 2011 & \cite{pradeep2011diagonal}\\ \hline
Convolutional neural network committees for handwritten character classification. & 381 & 2011 & \cite{ciresan2011convolutional}\\ \hline
Handwritten English character recognition using neural network. & 128 & 2011 & \cite{patil2011handwritten} \\ \hline
DRAW: A recurrent neural network for image generation.  & 995 & 2015 & \cite{gregor2015draw}\\ \hline
Online and off-line handwriting recognition: a comprehensive survey.   & 2909 & 2000 & \cite{plamondon2000online}\\ \hline
Template-based online character recognition.   & 173 & 2001 & \cite{connell2001template}\\ \hline
An overview of character recognition focused on off-line handwriting. & 589 & 2001 & \cite{arica2001overview} \\ \hline
IFN/ENIT-database of handwritten Arabic words.& 477 & 2002 &\cite{pechwitz2002ifn}\\ \hline
Off-line Arabic character recognition–a review.& 236 & 2002 &\cite{khorsheed2002off}\\ \hline
A class-modular feedforward neural network for handwriting recognition. & 131 & 2002 &\cite{oh2002class}\\ \hline
Individuality of handwriting. & 552 & 2002 &\cite{srihari2002individuality}\\ \hline
HMM based approach for handwritten Arabic word recognition using the IFN/ENIT-database. & 172 & 2003 & \cite{pechwitz2003hmm}\\ \hline
Handwritten digit recognition: benchmarking of state-of-the-art techniques. & 573 & 2003 & \cite{liu2003handwritten}\\ \hline
Indian script character recognition: a survey. & 540 & 2004 & \cite{pal2004indian}\\ \hline
Online recognition of Chinese characters: the state-of-the-art. & 362 & 2004 &\cite{liu2004online}\\ \hline
A study on the use of 8-directional features for online handwritten Chinese character recognition. & 145 & 2005 & \cite{bai2005study}\\ \hline
Offline Arabic handwriting recognition: a survey. & 551 & 2006 & \cite{lorigo2006offline}\\ \hline
Recognition of off-line handwritten devnagari characters using quadratic classifier. & 168 & 2006 & \cite{sharma2006recognition}\\ \hline
Connectionist temporal classification: labeling unsegmented sequence data with RNN. & 1404 & 2006 & \cite{graves2006connectionist}\\ \hline
Text-independent writer identification and verification on offline arabic handwriting. & 128 & 2007 & \cite{bulacu2007text}\\ \hline
A novel approach to on-line handwriting recognition based on bidirectional LSTM networks. & 172 & 2007 & \cite{liwicki2007novel}\\ \hline
Fuzzy model based recognition of handwritten numerals. & 148 & 2007 & \cite{hanmandlu2007fuzzy}\\ \hline
Introducing a very large dataset of handwritten Farsi digits and a study on their varieties. & 155 & 2007 & \cite{khosravi2007introducing}\\ \hline
Unconstrained on-line handwriting recognition with recurrent neural networks & 207 & 2007 & \cite{graves2008unconstrained}\\ \hline
ICDAR 2013 Chinese handwriting recognition competition. & 177 & 2013 & \cite{yin2013icdar}\\ \hline


Automatic segmentation of the IAM off-line database for handwritten English text. &101 &2002 &\cite{zimmermann2002automatic}\\ \hline
\caption{Research publications with more than 100 citations}
\end{longtable}
\end{landscape}





\subsection{Temporal view}


\begin{figure}[!htb]
\centering
	\includegraphics[scale=0.75]{temporal.pdf}
	\caption{Publications Over The Years. On the $y$-axis is the number of publications. }
	\label{fig:figure 5}
	
\end{figure}



The distribution of number of studies over the period under study (2000 - 2018) can be seen in Figure \ref{fig:figure 5}. According to the reference figure, it can be noticed that there is a variation in the publication count through these years. Statistics show sudden increase in number of publications in the domain of a handwritten character recognition in the years 2002, 2007 and 2009. The number of publications remained steady in the remaining years of 2000s. After 2010 there is again steady increase in the number publications i.e. 59 publications in last 8 years.  Year 2017 and 2018 have seen a steady rise in number of publications. This is conceivably not surprising, since the concept of a handwritten character recognition is catching interest of more researcher because of the advancement of the research work in the fields of deep learning and computer vision. We believe that application areas of Handwritten OCRs will further increase in the coming years. 



\subsection{Language specific research} \label{LSR}

\begin{figure}[!htb]
	\centering
		\includegraphics [scale=0.75]{languages.pdf}
	\caption{Number of selected studies with respect to investigated language. Numeric value within bar shows number of  selected studies for the given language.}
	\label{fig:figure 6}
\end{figure}


The distributions / number of selected studies with respect to investigated scripting languages are shown in the Figure \ref{fig:figure 6}. Total number of selected studies are 142 and out of these 142 studies, English language has the highest contribution of 45 studies in the domain of character recognition, 40 studies related to Arabic language, 26 studies are on the Indian scripts, 17 on Chinese language, 14 on Urdu language, while 11 studies were conducted on Persian language. Some of the selected articles discussed multiple languages. 

Figure \ref{fig:figure 7} represents publications count each year with respect to language. Reference figure shows compiled temporal view of handwritten OCR researches done in different languages throughout the mentioned era of 2000-2018, in this time period there are certain research articles that covers more than one language of handwritten OCR. 





\begin{figure}[!htb]
	\centering
		\includegraphics  [scale=0.7]{diffLangaugeOveryear.pdf}
	\caption{Selected studies count each year with respect to specific language. $y$-axis shows the number of selected studies. Specific color within each bar represents specific language as shown in the legend.}
	\label{fig:figure 7}
\end{figure}






\section{Research questions} \label{RQ}
Research questions play an important role in systematic literature review, because these questions determine the search queries and keywords that will be used to explore research publications. As discussed above, we chose research questions which not only help  seasoned researchers but also to researchers entering in the domain of optical character recognition to understand where the research in this field stands as of today. This review article answers research questions presented in Table \ref{Tab:RQs}. Reference table also presents motivation for each research question.  

\begin{table} [!htb]
\centering
	
	\caption{Research questions and motivation}
	\begin{tabular}{| p{8cm} |  p{8cm} |}
		\hline
		\textbf{Research question}  & \textbf{Motivation} \\ \hline
		
		What different feature extraction and classifications methods are used for handwritten OCR?  & To identify trends in used feature extractors and machine learning techniques over almost two decades.  \\ \hline
		
		


		
		What different datasets / databases are  available for research purpose?  & Availability of a dataset with enough data is always fundamental requirement for buidling OCR system \cite{KHAN201961}  \\ \hline
		
		
		What major languages are investigated?   & To highlight which languages have usually been investigated. Thus identifying languages which needs more research attention. \\ \hline
		
		What are the new research domains in the area of OCR?   & To provide guidance for new research projects.  \\ \hline
		
	\end{tabular}
\label{Tab:RQs}
\end{table}











\section{Classification methods of handwritten OCR} \label{classi}

In handwritten OCR an algorithm is trained on a known dataset and it discovers how to accurately categorize / classify the alphabets and digits. Classification is a process to learn model on a given input data and map or label it to predefined category or classes \cite{Mitchell}. In this section we have discussed most prevalent classification techniques in OCR research studies beginning from 2000 till 2018. 



\subsection{Artificial Neural Networks (ANN)}

Biological neuron inspired architecture, Artificial Neural Networks (ANN) consists of numerous processing units called neurons \cite{NNBook}. These processing elements (neurons) work together to model given input data and map it to predefined class or label \cite{vithlani2015study}. The main unit in neural networks is nodes (neuron). Weights associated with each node are adjusted to reduce the squared error on training samples in a supervised learning environment (training on labeled samples / data). Figure \ref{fig:figure 12} presents pictorial representation of Multi Layer Perceptron (MLP) that consists of three layers i.e. (input, hidden and output).



Feed forward networks / Multi Layer Perceptron (MLP) achieved renewed interest of research community in mid 1980s as by that time ``Hopfield network'' provided the way to understand human memory and calculate state of a neuron \cite{485891}. Initially, computational complexity of finding weights associated with neurons hindered application of neural networks. With the advent of deep (many layers) neural architectures i.e.  Recurrent Neural Network (RNN) and Convolutional Neural Networks (CNN), neural networks has established it self as one of the best classification technique for recognition tasks including OCR \cite{nawaz2003approach,srihari2007offline,pradeep2012neural,singh2011feature}. Refer Sections \ref{future} and \ref{fworks} for current and future research trends.  

 


\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.27]{Fig12_MLP.pdf}
	\caption {An architecture of Multilayer Perceptron (MLP) \cite{RizHam}}
	\label{fig:figure 12}
\end{figure}  


The early implementation of MLP in handwritten OCR was done by shamsher et al. \cite{shamsher2007ocr} on Urdu language. The researchers proposed feed forward neural network algorithm of MLP (Multi Layer Preceptrons) \cite{al2009handwriting}. Liu et al. \cite{liu2009new} used MLP on Farsi and Bangla numerals. One hidden layer was used with the connecting weights estimated by the error back-propagation (BP) algorithm that minimized the squared error criterion. On the other hand, Ciresan et al \cite{cirecsan2010deep} trained five MLPs with two to nine hidden layers and varying numbers of hidden units for the recognition of English numerals.


Recently, Convolutional Neural Network (CNN) has reported great success in character recognition task \cite{liu2005classification}. Convolutional neural network has been widely used for classification and recognition of almost all the languages that have been reviewed for this systematic literature review \cite{boufenar2018investigation,sokar2018generic,lin2018chinese,yang2018recognition,alizadehashraf2017persian,ghasemi2018persian}.





\subsection{Kernel methods}

A number of powerful kernel-based learning models, e.g. Support Vector Machines (SVMs), Kernel Fisher Discriminant Analysis (KFDA) and Kernel Principal Component Analysis (KPCA) have shown practical relevance for classification problems. For instance, in the context of optical pattern, text categorization, time-series prediction these models have significant relevance. 



In support vector machine, kernel performs mapping of feature vectors into a higher dimensional feature space in order to find a hyperplane, which is linearly separates classes by as much margin as possible. Given a training set of labeled examples \{ ($x_i, y_i$) , $i$ = 1 \dots $l$ \} where $x_i$ $\in$ $\Re^n$ and $y_i$ $\in$ \{-1, 1\}, a new test example $x$ is classified by the following function:


\begin{equation}
f(x)=sgn(\sum\limits_{i=1}^{l} \alpha_i y_i K(x_i,x)+b)
\end{equation}

where:
\begin {enumerate}
\item $K(.,.)$ is a kernel function
\item $b$ is the threshold parameter of the hyperplane
\item $\alpha_i$ are Langrange multipliers of a dual optimization problem that describe the separating hyperplane
\end {enumerate}


Before popularization of deep learning methodology, SVM was one of the most robust technique for handwritten digit recognition, image classification, face detection, object detection, and text classification \cite{boukharouba2017novel}. Kernel Fisher Discriminant Analysis (KFDA) and Kernel Principal Component Analysis (KPCA) are also some of the most significant kernel methods being used in offline handwritten character recognition system \cite{verma2012survey}.


Boukharouba et al. \cite{boukharouba2017novel,yang2005discrimination} used SVM for recognition of Urdu and Arabic handwritten digits. SVMs have also been successfully implement in image classification and affect recognition \cite{yang2009linear, KHAN20131159}, text classification \cite{haddoud2016combining} and face and object detection\cite{ning2016object,tao2016robust}. 








\subsection{Statistical methods}
Statistical classifiers can be parametric and non-parametric. Parametric classifiers have fixed (finite) number of parameters and their complexity is not a function of size of input data. Parametric classifiers are generally fast in learning concept and can even work with small training set. Example of parametric classifiers are Logistic Regression (LR), Linear Discriminant Analysis (LDA), Hidden Markov Model (HMM) etc.


On the other hand, non-parametric classifiers are more flexible in learning concepts but usually grow in complexity with the size of input data.  $K$ Nearest Neighbor ($K$NN), Decision Trees (DT) are examples of non-parametric techniques as as their number of parameters grows with the size of the training set.




\subsubsection{Non-parametric statistical methods}
One of the most used and easy to train statistical model for classification is $k$ nearest neighbor ($k$NN) \cite{liu2003handwritten,akbari2018novel,chandio2018character}. It is a non-parametric statistical method, which is widely used in optical character recognition. Non-parametric recognition does not involve a-priori information about the data.

$k$NN finds number of training samples closest to new example based on target function. Based upon the value of targeted function, it infers the value of output class. The probability of an unknown sample $q$ belonging to class $y$ can be calculated as follows: 



\begin{equation}\label{KNN}
p (y\mid q) = \frac {\sum_ {k \epsilon K} W_{k} .1_{(k_{y}=y)}}{\sum_ {k \epsilon K} W_{k}}
\end{equation}

\begin{equation}\label{KNNS}
W_{k}= \frac {1} {d(k,q)}
\end{equation}

$where$;

\begin {enumerate}
\item $K$ is the set of nearest neighbors
\item $k_{y}$ the class of $k$
\item $d(k,q)$ the Euclidean distance of $k$ from $q$, respectively.
\end {enumerate}







Researchers have been found to use  $k$NN for over a decade now and they believe that this algorithm achieves relatively good performance for character recognition in their experiments performed on different datasets \cite{pradeep2012neural, lorigo2006offline, chandio2018character, kumar2018improved}. 

$k$NN classifies object / ROI based on majority vote of its neighbors (class) as it assigns class most prevalent among its $k$ nearest neighbors. If k = 1, then the object is simply assigned to class of that single nearest neighbor \cite{vithlani2015study}.



\subsubsection{Parametric statistical methods}

As mentioned above parametric techniques models concepts using fixed (finite) number of parameters as they assume sample population / training data can be modeled by a probability distribution that has a fixed set of parameters. In OCR research studies, generally characters are classified according to some decision rules such as maximum likelihood or Bayes method once parameters of model are learned \cite{arica2001overview}.












Hidden Markov Model (HMM) was one the most frequently used parametric statistical method earlier in 2000. 


HMM models system / data that is assumed to be Markov process with hidden states, where in Markov process probability of one states only depends on previous state \cite{arica2001overview}. It was first used in speech recognition during 1990s before researchers started using it in recognition of optical characters \cite{alma2002recognition, alma2004off, cheriet2008visual}. It is believed that HMM provides better results even when availability of lexicons is limited \cite{pechwitz2003hmm}. 
























\subsection{Template matching techniques}


\begin{figure} [!htb]
	\centering
	\includegraphics [scale=0.7]{Template.pdf}
	\caption{An overview of template matching techniques}
	\label{fig:figure 8}
\end{figure} 


As the names suggests, template matching is an approach in which images (small part of an image) is matched with certain predefined template. Usually template matching techniques employ sliding sliding window approach in which template image or feature are slided on the image to determine similarity between the two.  Based on used similarity (or distance) metric classification of different objects are obtained \cite{pal2012handwriting}. 

In OCR, template matching technique is used to classify character after matching it with predefined template(s) \cite{sahu2013offline}. In literature, different distance (similarity) metrics are used, most common ones are Euclidean distance, city block distance, cross correlation, normalized correlation etc. 

In template matching, either template matching technique employs rigid shape matching algorithm or deformable shape matching algorithm. Thus, creating different family of template matching. Taxonomy of template matching techniques is presented in Figure \ref{fig:figure 8}.






 










One of the most applicable approach for character recognition is deformable template matching (refer Figure \ref{fig:figure 9}) as different writers can write character by deforming them in particular way specific to writer. In this approach, deformed image is used to compare it with database of known images. Thus, matching / classification is performed with deformed shapes as specific writer could have deformed character in a particular way \cite{arica2001overview}. Deformable template matching is further divided into parametric and free form matching. Prototype matching, which is sub-class of parametric deformable matching, matching of done based on stored prototype (deformed) \cite{tiwari2012novel}.





\begin{figure} [!htb]
	\centering
	\includegraphics [height=5cm, width=8cm]{figure9.pdf}
	\caption{(a) Digit Deformations (b) Deformed Template superimposed on target image \cite{arica2001overview}}
	\label{fig:figure 9}
\end{figure} 
























Apart from deformable template matching approach, second sub-class of template matching is rigid template matching. As the name suggests, rigid template matching does not take into account shape deformations. This approach usually works with features extraction / matching of image with template. One of the most common approach used in OCR to extract shape features is Hough transform, like Arabic \cite{4376996} and Chinese \cite{Li1995}.

Second sub-class of rigid template matching is correlation based matching. In this technique, initially image similarity is calculated and based on similarity features from specific regions are extracted and compared \cite{arica2001overview, chaudhuri2010some}. 












\subsection{Structural pattern recognition}
Another classification technique that was used by OCR research community before the popularization of kernel methods and neural networks / deep learning  approach was structural pattern recognition. Structural pattern recognition aims to classify objects based on relationship between its pattern structures and usually structures are extracted using pattern primitives (refer Figure \ref{fig:graph} for an example of pattern primitives) i.e. edge, contours, connected component geometry etc . One of such image primitive that has been used in OCR is Chain Code Histogram (CCH) \cite{bookCCH, LIU2004265}. CCH effectively describes image / character boundary / curve, thus helping in classify character \cite{boukharouba2017novel, vithlani2015study}. Prerequisite condition to apply CCH for OCR is that image should be in binary format and boundaries should be well define. Generally, for handwritten character recognition this condition makes CCH difficult to use. Thus, different research studies and publicly available datasets use / provide binarized images \cite{akbari2018novel}. 


\begin{figure} [!htb]
	\centering
	\includegraphics [scale=0.75]{graph.pdf}
	\caption{(a) Primitive and relations (b) Directed graph for capital letter R and E \cite{Marquesde2001}}
	\label{fig:graph}
\end{figure} 


In research studies of OCR, structural models can be further sub-divided on the basis of context of structure i.e. graphical methods and grammar based methods . Both of these models are presented in next two sub-sections.














\subsubsection{Graphical methods}

A graph ($G$) is a way to mathematically describe relation between connected objects and is represented by ordered pair of nodes ($N$) and edges ($E$). Generally for OCR, $E$ represents arc of writing stroke connecting $N$. The particular arrangement  of $N$ and $E$ define characters / digits / alphabets. Trees (undirected graph, where direction of connection is not defined), directed graphs (where direction of edge to node is well defined) are used in different research studies to represent characters mathematically \cite{rohtua, ALVARO201458}. 

As mentioned above, writing structural components are extracted using pattern primitives i.e. edge, contours, connected component geometry etc. Relation between these structures can be defined mathematically using graphs (refer Figure \ref{fig:graph} for an example showing how letter ``R'' and ``E'' can be modeled using graph theory). Then considering specific graph architecture different structures can be classified using graph similarity measure i.e. similarity flooding algorithm \cite{994702}, SimRank algorithm \cite{Jeh:2002}, Graph similarity scoring \cite{ZAGER200886} and vertex similarity method \cite{Leicht2006}. In one study \cite{8263187}, graph distance is used to segment overlapping and joined characters as well.   















\subsubsection{Grammar based methods}

In graph theory, syntactic analysis is also used to find similarities in graph structural primitives using concept of grammar \cite{grammar}. Benefit of using grammar concepts in finding similarity in graphs comes from the fact that this area is well researched and techniques are well developed.  There are different types of grammar based on restriction rules, for example unrestricted grammar, context-free grammar, context-sensitive grammar and regular grammar. Explanation of these grammar and corresponding applied restrictions are out scope of this survey article. 

In OCR literature, usually strings and trees are used to represent models based on grammar.  With well defined grammar, string is produced that then can be robustly classified to recognize character. Tree structure can also models hierarchical relations between structural primitives \cite{pal2012handwriting}. Trees can also be classified by analyzing grammmar that defines the tree, thus classifying specific character \cite{Chaudhuri2017}. 











\section{Datasets}\label{dataset}

Generally, for evaluating and benchmarking different OCR algorithms, standardized databases are needed / used to enable a meaningful comparison \cite{KHAN201961}. Availability of a dataset containing enough amount of data for training and testing purpose is always fundamental requirement for a quality research \cite{hussain2015comprehensive, Khan2011b}. Research in the domain of optical character recognition mainly revolves around six different languages namely, English, Arabic, Indian, Chinese, Urdu and Persian / Farsi script. Thus, there are publicly available datasets for these languages such as MNIST, CEDAR, CENPARMI, PE92, UCOM, HCL2000 etc. 



Following subsections presents an overview of most used datasets for above mentioned languages. 

\subsection{CEDAR}


\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.15]{figure16.pdf}
	\caption{Sample image from CEDAR Dataset \cite{liu2003handwritten}}
	\label{fig:figure 16}
\end{figure} 

This legacy dataset, CEDAR, was developed by the researchers at University of Buffalo in 2002 and is considered among the first few large databases of handwritten characters \cite{srihari2002individuality}. In CEDAR the images were scanned at 300 dpi. Example character images from CEDAR database are shown in Figure \ref{fig:figure 16}.







\subsection{MNIST}


\begin{figure} [!htb]
	\centering
	\includegraphics [scale=0.6]{figure17.pdf}
	\caption{Sample handwritten digits from MNIST Dataset \cite{liu2003handwritten}}
	\label{fig:figure 17}
\end{figure} 


The MNIST dataset is considered as one of the most used / cited dataset for handwritten digits \cite{liu2003handwritten, hangarge2010offline, cirecsan2010deep, liu2002handwritten, vamvakas2008hierarchical, babu2014handwritten}. It is the subset of  the NIST dataset and that is why it is called modified NIST or MNIST. The dataset consist of 60,000 training and 10,000 test images. Samples are normalized into 20 x 20 grayscale images with reserved aspect ratio and the normalized images are of size 28 x 28. The dataset greatly reduces the time required for pre-processing and formatting, because it is already in a normalized form. 




\subsection{UCOM}
The UCOM is an Urdu language dataset available for research \cite{ahmed2017ucom}. The authors claim that this dataset could be used for both character recognition as well as writer identification.  The dataset consists of 53,248 characters and 62,000 words written in nasta'liq (calligraphy) style, scanned at 300 dpi. The dataset was created based on the writing of 100 different writers where each writer wrote 6 pages of A4 size. The dataset evaluation is based on 50 text line images as train dataset and 20 text line images as test dataset with reported error rate between 0.004 -0.006\%. Example characters from the dataset are presented in Figure \ref{fig:figure 18}.


\begin{figure} [!htb]
	\centering
	\includegraphics [scale=0.6]{figure18.pdf}
	\caption{Example hand written characters from UCOM Dataset \cite{ahmed2017ucom}}
	\label{fig:figure 18}
\end{figure} 



\subsection{IFN/ENIT}

The IFN/ENIT \cite{pechwitz2002ifn} is the most popular Arabic database of handwritten text. It was developed in 2002 by the researchers at Technical University Braunschweig, Germany for advancement of research and development of Arabic handwriting recognition systems. The dataset contains 26459 handwritten images of the names of towns and villages in Tunisia. These images consist of 212,211 characters written by 411 different writers, refer Figure \ref{fig:figure 19}. Since inception, the dataset has been widely used by the researchers for the efficient recognition of Arabic characters \cite{pechwitz2003hmm,el2007ifn,margner2007arabic,bulacu2007text}.

\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.8]{figure19.pdf}
	\caption{Sample writings from IFN/ENIT Dataset \cite{pechwitz2002ifn}}
	\label{fig:figure 19}
\end{figure} 




\subsection{CENPARMI}

The CENter for PAttern Recognition and Machine Intelligence (CENPARMI) introduced first version of Farsi dataset in 2006 \cite{khosravi2007introducing,solimanpour2006standard} . This dataset contains 18,000 samples of Farsi numerals. These numerals are divided into 11,000 training, 2,000 verification and 5,000 samples for testing purpose. 

Another similar, but larger dataset of Farsi numerals was produced by Khosravi \cite{khosravi2007introducing} in 2007. This dataset contains 102,352 digits extracted from registration forms of high school and undergraduate students. Later in 2009 \cite{haghighi2009new}, CENPARMI released another larger, extended version of Farsi dataset. This larger dataset contains 432,357 images of dates, words, isolated letters, isolated digits, numeral strings, special symbols, and documents. Refer Figure \ref{fig:figure 20} for examples images from CENPARMI Farsi language dataset.




\begin{figure} [!htb]
	\centering
	\includegraphics [scale=0.5]{figure20.pdf}
	\caption{CENPARMI dataset example images \cite{khosravi2007introducing}}
	\label{fig:figure 20}
\end{figure} 




\subsection{HCL2000}

The HCL2000 is an handwritten Chinese character database, refer Figure \ref{fig:figure 21} to see sample images. The dataset is publicly available for researchers. The dataset contains 3,755 frequently used Chinese characters written by 1,000 different subjects. The database is unique in a way that it contains two sub datasets, one is handwritten Chinese characters dataset, while the other is corresponding writer's information dataset. This information is provided so that research can be conducted not only based on the character recognition, but also on writer's background such as age, gender, occupation and education \cite{zhang2009hcl2000}.


\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.6]{figure21.pdf}
	\caption{HCL2000 dataset sample images \cite{zhang2009hcl2000}}
	\label{fig:figure 21}
\end{figure} 


\subsection{IAM}
The IAM \cite{marti2002iam} is handwritten database of English language based on  Lancaster-Oslo/Bergen (LOB) corpus. Data were collected from 400 different writers who produced 1,066 forms of English text containing vocabulary of 82,227 words. Data consists of full English language sentences. The dataset was also used for writer identification \cite{bulacu2007text}. Researchers were able to successfully identify writer 98\% of the time during experiments on IAM dataset. Writing sample from the IAM dataset are presented in Figure  \ref{fig:figure 22}. 






\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.5]{figure22.pdf}
	\caption{Sample Image IAM dataset \cite{marti2002iam}}
	\label{fig:figure 22}
\end{figure}  





\section{Languages} \label{lang}
As mentioned above, researchers working in the domain of optical character recognition have mainly investigated six different languages, which are English, Arabic, Indian, Chinese, Urdu and Persian. This is one of the future work to built OCR systems for other languages as well.  


\begin{figure}[!htb]
	\centering
	\includegraphics [scale=0.78]{endangLang.pdf}
	\caption{Data from UNESCO's report on ``world's languages in danger'' \cite{Danger}.}
	\label{fig:endang}
\end{figure} 


According to the United Nations Educational, Scientific and Cultural Organization (UNESCO) report on ``world's languages in danger'' at least 43\% of languages spoken in the world are endangered \cite{Danger}. These large number of languages need attention of OCR research community as well to preserve this heritage from extinction or at least to built such system that translates documents from endangered languages to electronic form for reference.  Data from UNESCO's report on ``world's languages in danger'' is presented in Figure \ref{fig:endang}.





This section presents state-of-the art results for six language which are usually studied by researchers. 

 

\subsection{English language}

English Language is the most widely used language in the world. It is the official language of 53 countries and articulated as a first language by around 400 million people. Bilinguals use English as an international language. Character recognition for English language has been extensively studied throughout many years. In this systematic literature review, English language has the highest number of publications i.e. 45 publications after concluding study selection process (refer Section \ref{SSP} and Section \ref{LSR}). The OCR systems for English language occupy a significant place as large number of studies have been done in the era of 2000-2018 on English language.

The English language OCR systems have been used successfully in a wide array of commercial applications. The most cited study for English language handwritten OCR is by Plamondon et al. \cite{plamondon2000online} in 2000, which have more than 2900 citations , refer Table \ref{Tab:Table 3}. The objective of the research by Plamondon et al. was to present a broad review of the state of the art in the field of automatic processing of handwriting. This paper explained the phenomenon of pen based computers and achieve the goal of automatic processing of electronic ink by mimicking and extending the pen paper metaphor. To identify the shape of the character, structural and rule based models like (SOFM) self-organized feature map, (TDNN) time delay neural network and (HMM) hidden markov model was used. 




Another comprehensive overview on character recognition presented in \cite{arica2001overview} by Arica et al. has more than 500 citations. Arica et al. concluded that characters are natural entities and it is  practically impossible for character recognition to impose strict mathematical rule on the patterns of characters. Neither the structural nor the statistical models can signify a complex pattern alone. The statistical and structural information for many characters pattern can be combined by neural networks (NNs) or harmonic markov models (HMM). 

Connell et al. \cite{connell2001template} demonstrated a template-based system for online character recognition, which is capable of representing different handwriting styles of a particular character. They used decision trees for efficient classification of characters and achieve 86\% accuracy. 


Every language has specific way of writing and have some diverse features that distinguished it with other language. We believe that to efficiently recognize handwritten and machine printed text of the English language, researchers have used almost all of the available feature extraction and classification techniques. These feature extraction and classification techniques include but not limited to HOG \cite{tian2016multilingual} , bidirectional LSTM \cite{toselli2016hmm}, directional features \cite{deshmukh2009analysis},  multilayer perceptron (MLP) \cite{ahlawat2017off,liu2002handwritten,sharma2013performance}, hidden markov model(HMM) \cite{zimmermann2002automatic,graves2008unconstrained,graves2009novel,pradeep2012neural}, Artificial neural network (ANN) \cite{patel2011handwritten,zhang2007novel,saha2013optical} and support vector machine (SVM) \cite{liu2005classification,vamvakas2010handwritten}. 

Recently trend is shifting away from using handcrafted features and moving towards deep neural networks. Convolutional Neural Network (CNN) architecture, a class of deep neural networks, has achieved classification results that exceeds state-of-the-art results specifically for visual stimuli / input \cite{avadesh2018optical}. LeCun \cite{DL} proposed CNN architecture based on multiple stages where each stage is further based on multiple layers. Each stage uses feature maps, which are basically arrays containing pixels. These pixels are fed as input to multiple hidden layers for feature extraction and a connected layer, which detects and classifies object \cite{KHAN201961}.  








\subsection{Farsi / Persian script}
Farsi, also known as Persian Language is mainly spoken in Iran and partly in Afghanistan, Iraq, Tajikistan and Uzbekistan by approximately 120 million people. The Persian script is considered to be similar to Arabic, Urdu, Pashto and Dari languages.  Its nature is also cursive so the appearance of the letter changes with respect to positions. The script comprises of 32 characters and unlike Arabic language, the writing direction of the Farsi language is mostly but not exclusively from right to left. 

Mozaffari et. al \cite{mozaffari2004recognition} proposed a novel handwritten character recognition method for isolated alphabets and digits of Farsi and Arabic language by using fractal codes. On the basis of the similarities of the characters they categorized the 32 Farsi alphabets into 8 different classes. A multilayer perceptron (MLP) (refer Figure \ref{fig:figure 12} for overview of MLP)  was used as a classifier for this purpose. The classification rate for characters and digits were 87.26\% and 91.37\% respectively. 


However, in another research \cite{soltanzadeh2004recognition}, researchers achieved recognition rate of 99.5\% by using RBF kernel based support vector machine. Broumandnia et al. \cite{broumandnia2007fast} conducted research on Farsi character recognition and claims to propose the fastest approach of recognizing Farsi character using Fast Zernike wavelet moments and artificial neural networks (ANN). This model improves on average recognition speed by 8 times. 



Liu et al. \cite{liu2009new} presented results of handwritten Bangla and Farsi numeral recognition on binary and gray scale images. The researchers applied various character recognition methods and classifiers on the three public datasets such as ISI Bangla numerals, CENPARMI Farsi numerals, and IFHCDB Farsi numerals and claimed to have achieved the highest accuracies on the three datasets i.e. 99.40\%, 99.16\%, and 99.73\%, respectively. 

In another research Boukharouba and Bennia \cite{boukharouba2017novel} proposed SVM based system for efficient recognition of handwritten digits. Two feature extraction techniques namely chain code histogram (CCH) \cite{cch} and white-black transition information were discussed. The feature extraction algorithm used in the research did not require digits to be normalized. SVM classifier along with RBF kernel method was used for classification of handwritten Farsi digits named ‘hoda’. This system maintains high performance with less computational complexity as compared to previous systems as the features used were computationally simple.

Lately, as discussed above researchers are using Convolutional Neural Network (CNN) in conjunction with other techniques for the recognition of characters. These techniques are being applied on different datasets to check the accuracy of techniques \cite{sokar2018generic, akbari2018novel, ghasemi2018persian, alizadehashraf2017persian}.




\subsection{Urdu language}

Urdu is curvasive language like Arabic, Farsi and many others \cite{naz2014optical}.  An early notable attempt to improve the methods for Urdu OCR is by Javed et al. in 2009 \cite{javed2009improving}. Their study focuses on the Nasta'liq (calligraphy) style specific pre-processing stage in order to overcome the challenges posed by the Nasta'liq style of Urdu handwriting. The steps proposed include page segmentation into lines and further line segmentation into sub-ligatures, followed by base identification and base-mark association. 94\% of the ligatures were accurately separated with proper mark association. 

Later in 2009, the first known dataset for Urdu handwriting recognition was developed at Centre for Pattern Recognition and Machine Intelligence (CENPARMI) \cite{sagheer2009new}. Sagheer et al. \cite{sagheer2009new} focused on the methods involving data collection, data extraction and pre-processing. The dataset stores dates, isolated digits, numerical strings, isolated letters, special symbols and 57 words. As an experiment, Support Vector Machine (SVM) using a Radial Base Function / kernel (RBF) was used for classification of isolated Urdu digits. The experiment resulted in a high recognition rate of 98.61\%.


To facilitate multilingual OCR, Hangarge et al. \cite{hangarge2010offline} proposed a texture-based method for handwritten script identification of three major scripts: English, Devnagari and Urdu. Data from the documents were segmented into text blocks and / or lines. In order to discriminate the scripts, the proposed algorithm extracts fine textural primitives from the input image based on stroke density and pixel density. For experiments, $k$-nearest neighbor classifier was used for classification of the handwritten scripts. The overall accuracy for tri-script and bi-script classification peaked up to 88.6\% and 97.5\% respectively. 


A study by Pathan et al. \cite{pathan2012recognition} in 2012 proposed an approach based on invariant moment technique to recognize the handwritten isolated Urdu characters. A dataset comprising of 36800 isolated single and multi-component characters was created. For multi-component letters, primary and secondary components were separated, and invariant moments were calculated for each. The researchers used SVM for classification, which resulted an overall performance rate of 93.59\%. Similarly, Raza et al. \cite{raza2012unconstrained} created an offline sentence database  with automatic line segmentation. It comprises of 400 digitised forms by 200 different writers. 

Obaidullah et al. \cite{obaidullah2015numeral} proposed a handwritten numeral script identification (HNSI) framework to identify numeral text written in Bangla, Devanagari, Roman and Urdu. The framework is based on a combination of daubechies wavelet decomposition \cite{Daub} and spatial domain features. A dataset of 4000 handwritten numeral word image for these scripts was created for this purpose. In terms of average accuracy rate, multi-layer perceptron (MLP) (refer Figure \ref{fig:figure 12} for pictorial depiction of MLP) proves to be better than NBTree, PART, Random Forest, SMO and Simple Logistic classifiers.

 




In 2018, Asma and Kashif \cite{Asma} presented  comparative analysis of raw images and meta features from UCOM dataset. CNN (Convolutional Neural Network) and a LSTM (Long short-term Memory), which is a recurrent neural network based architecture were used on Urdu language dataset. Researchers claim that CNN provided accuracy of 97.63\% and 94.82\% on thickness graph and raw images respectively. While, the accuracy of LSTM was 98.53\% and 99.33\%. 

In another study Naseer et al. \cite{naseer2018comparative} and Tayyab et al.  \cite{tayyab2018multi} proposed an OCR model based on CNN and BDLSTM (Bi-Directional LSTM). This model was applied on dataset containing urdu news tickers and results were compared with google's vision cloud OCR. researchers found that their proposed model worked better than google's cloud vision OCR in 2 of the 4 experiments.




\subsection{Chinese language}

Our research includes 17 research publications on the OCR system of Chinese language after concluding study selection process (refer Section \ref{SSP} and Section \ref{LSR}).  One of the Earliest research on Chinese language was done in 2000 by Fu et al. \cite{fu2000user}. The researchers used self-growing probabilistic decision-based neural networks (SPDNNs) to develop a user adaptation module for character recognition and personal adaption. The resulting recognition accuracy peaked up to 90.2\% in ten adapting cycles.

Later in 2005, a comparative study of applying feature vector-based classification methods to character recognition by Cheng and Fujisawa \cite{liu2005classification} found that discriminative classifiers such as artificial neural network (ANN) and support vevtor machin (SVM) gave higher classification accuracies than statistical classifiers when sample size was large. However, in the study SVM demonstrated better accuracies than neural networks in many experiments. 

In another study Bai and Huo \cite{bai2005study} evaluated use of 8-directional features to recognize online handwritten Chinese characters. Following a series of processing steps, blurred directional features were extracted at uniformly sampled locations using a derived filter, which forms a 512-dimensional vector of raw features. This, in comparison to an earlier approach of using 4-directional features, resulted in a much better performance.  



In 2009, Zhang \cite{zhang2009hcl2000} presented HCL2000, a large-scale handwritten Chinese Character database. It stores 3,755 frequently used characters along with the information of its 1000 different writers. HCL2000 was evaluated using three different algorithms; Linear Discriminant Analysis (LDA), Locality Preserving Projection (LPP) and Marginal Fisher Analysis (MFA). Prior to the analysis, a Nearest Neighbor classifier assigns input image to a character group. The experimental results show MFA and LPP to be better than LDA. 


Yin et al. \cite{yin2013icdar} proposed ICDAR 2013 competition which received 27 systems for 5 tasks – classification on extracted feature data, online/offline isolated character recognition and online/offline handwritten text recognition. Techniques used in the systems were inclusive of LDA, Modified quadratic discriminant function (MFQD), Compound Mahalanobis Function (CMF), convolutional neural network (CNN) and multilayer perceptron (MLP). It was explored that the methods based on neural networks proved to be better for recognizing both isolated character and handwritten text. 

During the study in 2016 on accurate recognition of multilingual scene characters, Tian et al. \cite{tian2016multilingual} proposed an extension of Histogram of Oriented Gradient (HOG), Co-occurrence HOG (Co-HOG) and Convolutional Co-HOG (ConvCo-HOG) features. The experimental results show the efficiency of the approaches used and higher recognition accuracy of multilingual scene texts. 

In 2018, researchers on Chinese script used neural networks to recognize CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) recognition \cite{lin2018chinese}, Medical document recognition \cite{zhao2018multi}, License plate recognition \cite{luo2018multiple} and text recognition in historical documents \cite{yang2018recognition}. Researchers used Convolutional Neural Network(CNN) \cite{lin2018chinese,yang2018recognition}, Convolutional Recurrent Neural Network(CRNN) \cite{zhao2018multi} and Single Deep Neural Network(SDNN) \cite{luo2018multiple} during these studies. 





\subsection{Arabic script}

Research on handwritten Arabic OCR systems has passed through various stages over the past two decades. Studies in the early 2000s focused mainly on the neural network methods for recognition and developed variants of databases \cite{mezghani2002line}. In 2002, Mario Pechwitz \cite{pechwitz2002ifn} developed the first IFN/ENIT-database to allow for the training and testing of Arabic OCR systems. This is one of the highly cited databases and has been cited more than 470 times. Another database was developed by Saeed Mozaffari \cite{mozaffari2006comprehensive,mozaffari2009icdar} in 2006. It stores gray-scale images of isolated offline handwritten 17,740 Arabic / Farsi numerals and 52,380 characters. Another notable dataset containing Arabic handwritten text images was introducted by Mezghani et al. \cite{mezghani2012database}. The dataset has open vocabulary written by multiple writers (AHTID / MW). It can be used for word and sentence recognition, and writer identification \cite{khayyat2014learning}. 


A survey by Lorigo and Govindaraju \cite{lorigo2006offline} provides a comprehensive review of the Arabic handwriting recognition methodologies and databases used until 2006. This includes research studies carried out on IFN/ENIT database. These studies mostly involved artificial neural networks (ANNs), Hidden Markov Models (HMM), holistic and segmentation-based recognition approaches. The limitations pointed out by the review included restrictive lexicons and restrictions on the text appearance. 




In 2009, Alex et al. \cite{graves2009offline} introduced a globally trained offline handwriting recognizer based on multi-directional recurrent neural networks and connectionist temporal classification. It takes raw pixel data as input. The system had an overall accuracy of 91.4\% which also won the international Arabic recognition competition. 

Another notable attempt for Arabic OCR was made by Lutf et al. \cite{lutf2014arabic} in 2014, which primarily focused on the specialty of Arabic writing system. The researcher proposed a novel method with minimum computation cost for Arabic font recognition based on diacritics. Flood-fill based and clustering based algorithms were  developed for diacritics segmentation. Further, diacritic validation is done to avoid misclassification with isolated letters. Compared to other approaches, this method is the fastest with an average recognition rate of 98.73\% for 10 most popular Arabic fonts.

 An Arabic handwriting synthesis system devised by Elarian et al. \cite{elarian2015arabic} in 2015 synthesizes words from segmented characters. It uses two concatenation models: Extended-Glyphs connection and the Synthetic-Extensions connection. The impact of the results from this system shows significant improvement in the recognition performance of an HMM based Arabic text recognizer. 

Hicham and Akram \cite{akram2016using} discussed an analytical approach to develop a recognition system based on HMM Toolkit (HTK). This approach requires no priori segmentation. Features of local densities and statistics are extracted using vertical sliding windows technique, where each line image is transformed into a series of extracted feature vectors. HTK is used in the training phase and Viterbi algorithm is used in the recognition phase. The system gave an accuracy of 80.26\% for words with “Arabic-numbers” database and 78.95\% with IFN / ENIT database.

In study conducted in 2016 by Elleuch et al. \cite{elleuch2016new}, convolutional neural network (CNN) based on support vector machine (SVM) is explored for recognizing offline handwritten Arabic. The model automatically extracts features from raw input and performs classification.  

In 2018, researchers applied technique of DCNN (deep CNN) for recognizing the offline and handwritten Arabic characters \cite{boufenar2018investigation}. An accuracy of 98.86\% was achieved when strategy of DCNN using transfer learning was applied on two datasets. In another similar study \cite{jebril2018recognition} an OCR technique based on HOG (Histograms of Oriented Gradient) \cite{ICME_Khan} for feature extraction and SVM for character classification was used on handwritten dataset. The dataset contained names of Jordanian cities, towns and villages yielded an accuracy of 99\%. However,  when the researchers used multichannel neural network for segmentation and CNN for recognition on machine printed characters, the experiments on 18pt font showed an overall accuracy of 94.38\%. 




\subsection{Indian script}
Indian script is collection of scripts used in the sub-continent namely Devanagari \cite{avadesh2018optical}, Bangla \cite{rabby2018bornonet}, Hindi \cite{dutta2017towards}, Gurmukhi \cite{singh2011feature}, Kannada \cite{sagar2008ocr} etc. One of the earliest research on Devanagari (Hindi) script was proposed in 2000 by Lehal and Bhatt \cite{lehal2000recognition}. The research was conducted on Devanagari script and English numerals. The researchers used data that was already in isolated form in order to avoid the segmentation phase. The research is based on statistical and structural algorithms \cite{kimura1991handwritten}. The results of Devanagari scripts were better than English numerals. Devanagari had recognition rate of 89\% with 4.5 confusion rate, while English numerals had recognition rate of 78\% with confusion rate of 18\%. 

Patil et. al \cite{patil2002neural} was the first researcher to use neural network approach for the identification of Indian documents. The researchers propose a system capable of reading English, Hindi and Kannada scripts. Modular neural network was used for script identification while a two stage feature extraction system was developed, first to dilate the document image and second to find average pixel distribution in the resulting images. 

Sharma et al. \cite{sharma2006recognition} proposed a scheme based on quadratic classifier for the recognition of Devanagari script. The researchers used 64 directional features based on chain code histogram \cite{cch} for feature recognition. The proposed scheme resulted in 98.86\% and 80.36\% accuracy in recognizing Devanagari characters and numeral respectively. Fivefold cross validation was used for the computation of results.

Two research studies \cite{hanmandlu2007fuzzy,hanmandlu2007input} presented in 2007 were based on use of fuzzy modeling for character recognition of Indian script. The researchers claim that the use of reinforcement learning on a small database of 3500 Hindi numerals helped achieve recognition rate of 95\%.

Another research carried out on Hindi numerals \cite{bhattacharya2009handwritten} used relatively large dataset of 22,556 isolated numeral samples of Devanagari and 23,392 samples of Bangla scripts. The researchers used three Multi-layer perceptron classifiers to classify the characters. In case of a rejection, a 4th perceptron was used based on the output of previous three perceptrons in a final attempt to recognize the input numeral.  The proposed scheme provided 99.27\% recognition accuracy vs the fuzzy modeling technique, which provided the accuracy of 95\%. 


Desai \cite{desai2010gujarati} used neural networks for the numeral recognition of Gujrati script. The researcher used a multi-layers feed forward neural network for the classification of digits. However, the recognition rate was low at 82\%. 

Kumar et al. \cite{garg2010s,garg2010new} proposed a method for line segmentation of handwritten Hindi text. An accuracy of 91.5\% for line segmentation and 98.1\% for word segmentation was achieved. Perwej et. al \cite{perwej2012machine} used back propagation based neural network for the recognition of handwritten characters. The results showed that the highest recognition rate of 98.5\% was achieved. Obaidullah et al. \cite{obaidullah2015numeral} proposed Handwritten Numeral Script Identification or HNSI framework based on four indic scripts namely, Bangla, Devanagari, Roman and Urdu. The researchers used  different classifiers namely NBTree, PART, Random Forest, SMO, Simple Logistic and MLP and evaluated the performance against the true positive rate. Performance of MLP was found to be better than the rest. MLP was then used for bi and tri-script identification. Bi-script combination of Bangla and Urdu gave the highest accuracy rate of 90.9\% on MLP, while the highest accuracy rate of 74\% was achieved in tri-script combination of Bangla, roman and Urdu. 


In a multi dataset experiment\cite{rabby2018bornonet}, researchers applied a lightweight model based on 13 layers of CNN with 2-sub layers on four datasets of Bangla language.  An accuracy of 98\%, 96.81\%, 95.71\%, and 96.40\% was achieved when model was applied on CMATERdb, ISI, BanglaLekha-Isolated dataset and mixed datasets respectively. CNN based model was also applied on ancient documents written in Devanagari or Sanskrit script in another study. Results, when compared with Google's vision OCR gave an accuracy of 93.32\% vs 92.90\%. 




\section{Research trends} \label{future}

Lately, the research in the domain of optical character recognition has moved towards deep learning approach \cite{naz2017urdu,al2018deep} with little to no emphasis on hand crafted features. In this section we have analyze research trend / techniques mainly used in the publications of last three years (2015-2018). Our analysis is summarized in Table \ref{Tab:Table 4}. 

Table \ref{Tab:Table 4} includes script under investigation, techniques or classification technique employed for OCR, year of publication and respective reference number. This table gives holistic view of how researchers working on some of the widely used languages are trying to solve the problem of optical character recognition. We can see that neural network, specially CNN is being used extensively for the recognition of optical characters. However, traditional techniques like SVM, HMM, SIFT etc. are also being used in conjunction with CNN. 

\begin{landscape}
	\begin{longtable}{| p{1.5cm} | p{16cm}| p{1.5cm}| p{1cm}|}
		
		
\toprule
		\label{Tab:Table 4}
		\textbf{Script}  &\textbf{Technique Employed}& \textbf{Year} &\textbf{ Ref} \\ \hline	
		
		\endhead
		\multicolumn{3}{@{}l}{\ldots \textit{continued on next page}}
		
		\endfoot
		\endlastfoot

Chinese English Indian & Two new feature descriptors Co-HoG and ConvCo-HoG based on Histogram of Oriented Gradient(HoG) based on CNN.  & 2016 & \cite{tian2016multilingual}\\ \hline
Chinese & Convolutional Neural Network(CNN), Long Short-Term Memory (LSTM), Hidden Markov Model(HMM) & 2016 & \cite{suryani2016benefits}\\ \hline
Chinese & Neural Network language model,  Convolutional Neural Networks  & 2017 & \cite{wu2017improving}\\ \hline
Chinese English Indian & BOW based representation for characters, DSN-SVM,HOG-SVM, FV-SVM  & 2017 & \cite{shi2017fisher}\\ \hline
Chinese English & Convolutional neural network (CNN) & 2017 & \cite{feng2017robust}\\ \hline
Chinese & Convolutional Neural Network (CNN) & 2018 & \cite{lin2018chinese}\\ \hline
Chinese & Convolutional-Recurrent Neural Network (CRNN) & 2018 & \cite{zhao2018multi}\\ \hline
Chinese & Single Deep Neural Network (SDNN) & 2018 & \cite{luo2018multiple}\\ \hline
Chinese & Recognition of Chinese Text in Historical Documents with Page-Level Annotations. CNN, CNN followed by LSTM & 2018 & \cite{yang2018recognition}\\ \hline


English Urdu Indian & Features: Discrete wavelet transforms (DWT), Daubechies wavelet transforms, textural and entropy features. Classifiers: NBTree, PART, LIBLinear, Random Forest, SMO, MLP & 2015 & \cite{obaidullah2015numeral}\\ \hline

English Indian & SVM and Shortest Path Algorithm &2017 &\cite{chaudhuri2017approach}\\ \hline

English & Heat Kernel Signature (HKS), HKS with SIFT and triangular mesh structure &2015 &\cite{zhang2015handwritten}\\ \hline


English & Long Short-Term Memory (LSTM) architecture & 2015 & \cite{gregor2015draw}\\ \hline


English & word graphs (WG) based Line-level keyword spotting (KWS). & 2016 & \cite{toselli2016hmm}\\ \hline


English & Recurrent Neural Network (RNN)  model with two multi-layer RNNs trained with Long Short Term Memory (LSTM) and connectionist temporal classification (CTC), CNN & 2017 & \cite{su2017accurate}\\ \hline
English & Box Approach, Mean, Standard Deviation, Centre of Gravity, Neural Network & 2017 & \cite{ahlawat2017off}\\ \hline


Arabic & Kashida features, width feature and Hidden Markov Model (HMM) & 2015 & \cite{elarian2015arabic}\\ \hline
Arabic & Elliptic grapheme codebook features, $X^2$ distance metric & 2015 & \cite{abdi2015model}\\ \hline
Arabic & Features of local densities and features statistics, Hidden Markov Model (HMM) & 2016 & \cite{akram2016using}\\ \hline
Arabic & Support Vector Machine(SVM), Convolutional Neural Network(CNN) & 2016 & \cite{elleuch2016new}\\ \hline
Arabic & Recurrent connectionist language modeling 	 &2017 &\cite{yousfi2017contribution}\\ \hline

Arabic & DCNN (Deep Convolutional neural network) & 2018 & \cite{boufenar2018investigation}\\ \hline

Arabic & Edge operators (Canny, Sobel, Prewitt, Roberts, and Laplacian of Gaussian), Transforms (Fourier (FFT), discrete cosine (DCT), Hough, and Radon), Texture features (Gray-level range and standard deviation, entropy of the gray-level distribution, and the properties of the gray-level co-occurrence matrix (GLCM)), Moments (Hu’s seven moments and Zernike moments) and Ensemble of Support Vector Machine(SVM) & 2018 & \cite{elanwar2018making}\\ \hline

Arabic & Histograms of Oriented Gradient (HOG) , SVM & 2018 & \cite{jebril2018recognition}\\ \hline
Arabic & Multi-Channel Neural Network (MCNN) & 2018 & \cite{radwan2018neural}\\ \hline
Arabic & Fast Automatic Hashing Text Alignment (FAHTA) &2018 & \cite{doush2018novel}\\ \hline
Arabic & Deep Siamese Convolutional Neural Network and SVM & 2018 & \cite{sokar2018generic}\\ \hline




Urdu & Hierarchical combination of Convolutional Neural Networks (CNN),  Multi-dimensional Long Short-Term Memory Neural Networks (MDLSTM)  & 2017 & \cite{naz2017urdu}\\ \hline
Urdu & BDLSTM (Bi-Directional Long Short-Term Memory),  Recurrent Neural Network (RNN) & 2018 & \cite{tayyab2018multi}\\ \hline
Urdu & Histogram of Oriented Gradient (HOG), Support Vector Machine (SVM), $k$ Nearest Neighbors ($k$NN), Random Forest (RF) and Multi-Layer Perceptron (MLP) & 2018 & \cite{chandio2018character}\\ \hline
Urdu & Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) & 2018 & \cite{naseer2018comparative}\\ \hline






Indian &  Multi-column Multi-scale Convolutional Neural Network (MMCNN)   &2017 &\cite{sarkhel2017multi}\\ \hline
Indian & Convolutional Neural Network (CNN) & 2018 & \cite{rabby2018bornonet}\\ \hline
Indian & Convolutional Neural Network (CNN) & 2018 & \cite{avadesh2018optical}\\ \hline
Indian & Histogram of oriented gradient (HOG) and Support Vector Machine (SVM) & 2018 & \cite{choudhury2018handwritten}\\ \hline
Indian & Convolutional Recurrent Neural Network (CRNN) with Spatial Transformer Network (STN) layer & 2018 & \cite{dutta2017towards}\\ \hline
Indian & Zoning, Discrete Cosine Transformations (DCT), gradient features, $k$ Nearest Neighbors ($k$NN), Support Vector Machine (SVM), Decision Tree and Random Forest & 2018 & \cite{kumar2018improved}\\ \hline



Persian & Chain Code Histogram (CCH), transition information in the vertical and horizontal directions,  Support Vector Machine(SVM) & 2017 & \cite{boukharouba2017novel}\\ \hline




Persian & Zoning, chain code, outer profile, crossing count, $k$ Nearest Neighbors ($k$NN), Artificial Neural Networks and Support Vector Machine (SVM) & 2018 & \cite{akbari2018novel}\\ \hline
Persian & Convolutional Neural Network (CNN) & 2018 & \cite{sarvaramini2018persian}\\ \hline
Persian & Convolutional Neural Network (CNN) & 2018 & \cite{ghasemi2018persian}\\ \hline



\caption{Summary of frequently used feature extraction and classification techniques: Data corresponding to last three years (2015-2018). Studies corresponding to ``Indian'' script do include research on scripts belonging to Devanagari, Bangla, Hindi, Gurmukhi, Kannada etc. }

\end{longtable}
\end{landscape}




\section{Conclusion and future work} \label{conclusion}

\subsection{Conclusion}

\begin{enumerate}
\item Optical character recognition has been around for last eight (8) decades. However, initially products that recognize optical characters were mostly developed by large technology companies. Development of machine learning and deep learning has enabled individual researchers to develop algorithms and techniques, which can recognize handwritten manuscripts with greater accuracy. 

\item In this literature review, we systematically extracted and analyzed research publications on six widely spoken languages. We explored that some techniques perform better on one script than on another e.g. multilayer perceptron classifier gave better accuracy on Devanagri and Bangla numerals \cite{bhattacharya2009handwritten, mozaffari2004recognition} but gave average results for other languages \cite{ahlawat2017off, liu2002handwritten, sharma2013performance}. The difference may have been due to the fact that how specific technique models different style of characters and quality of the dataset. 

\item Most of the published research studies propose solution for one language or even subset of a language. Publicly available datasets also include stimuli that are aligned well with each other and fail to incorporate examples that corresponds well with real life scenarios i.e. writing styles, distorted strokes, variable character thickness and illumination \cite{long2018}. 

\item  It was also observed that researchers are increasingly using Convolutional Neural Networks(CNN) for the recognition of handwritten and machine printed characters. This is due to the fact that CNN based architectures are well suited for recognition tasks where input is image. CNN were initially used for object recognition tasks in images e.g. the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) \cite{ILSVRC15}. AlexNet \cite{Krizhevsky1}, GoogLeNet \cite{7298594} and ResNet \cite{ResNet} are some of the CNN based architectures widely used for visual recognition tasks. 


\end{enumerate}




\subsection{Future work} \label{fworks}

\begin{enumerate}

\item As mentioned in Section \ref{lang}, research in OCR domain is usually done on some of the most widely spoken languages. This is partially due to non-availability of datasets on other languages. One of the future research direction is to conduct research on languages other than widely spoken languages i.e. regional languages and endangered languages. This can help preserve cultural heritage of vulnerable communities and will also create positive impact on strengthening global synergy.  


\item Another research problem that needs attention of research community is to built systems that can recognize on screen characters and text in different conditions in daily life scenarios e.g. text in captions or news tickers, text on sign boards, text on billboards etc. This is the domain of ``recognition / classification / text in the wild''. This is complex problem to solve as system for such scenario needs to deal with background clutters, variable illumination condition, variable camera angles, distorted characters and variable writing styles \cite{long2018}.

\item To build robust system for ``text in the wild'', researchers needs to come up with challenging datasets that is comprehensive enough to incorporate all possible variations in characters. One such effort is \cite{Yuan2019}. In another attempt, research community has launched ``ICDAR 2019: Robustreading challenge on multi-lingual scene text detection and recognition'' \cite{2019arXiv190700945N}. Aim of this challenge is invite research studies that proposes robust system for multi-lingual text recognition in daily life or ``in the wild'' scenario. Recently report for this challenge has been published and winner methods for different tasks in the challenge are all based on different deep learning architectures e.g. CNN, RNN or LSTM. 


\item Published research studies have proposed various systems for OCR but one aspect that needs to improve is commercialization of research. Commercialization of research will help building low cost real-life systems for OCR that can turn lots of invaluable information into searchable / digital data \cite{comm2008}.

\end{enumerate}
















\pagestyle{plain} 
































\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}\typeout{** loaded for the language `#1'. Using the pattern for}\typeout{** the default language instead.}\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Tappert}
\BIBentryALTinterwordspacing
C.~C. Tappert, C.~Y. Suen, and T.~Wakahara, ``The state of the art in online
  handwriting recognition,'' \emph{IEEE Transactions on Pattern Analysis and
  Machine Intelligence}, vol.~12, no.~8, pp. 787--808, Aug. 1990. [Online].
  Available: \url{http://dx.doi.org/10.1109/34.57669}
\BIBentrySTDinterwordspacing

\bibitem{Kumar2018}
M.~Kumar, S.~R. Jindal, M.~K. Jindal, and G.~S. Lehal, ``{Improved Recognition
  Results of Medieval Handwritten Gurmukhi Manuscripts Using Boosting and
  Bagging Methodologies},'' \emph{Neural Processing Letters}, pp. 1--14, 2018.

\bibitem{Radwan2018}
M.~A. Radwan, M.~I. Khalil, and H.~M. Abbas, ``{Neural Networks Pipeline for
  Offline Machine Printed Arabic OCR},'' \emph{Neural Processing Letters},
  vol.~48, no.~2, pp. 769--787, 2018.

\bibitem{HistMed}
P.~Thompson, R.~T. Batista-Navarro, G.~Kontonatsios, J.~Carter, E.~Toon,
  J.~McNaught, C.~Timmermann, M.~Worboys, and S.~Ananiadou, ``Text mining the
  history of medicine,'' \emph{PLOS ONE}, vol.~11, no.~1, pp. 1--33, Jan. 2016.

\bibitem{Ashley2010}
\BIBentryALTinterwordspacing
K.~D. Ashley and W.~Bridewell, ``Emerging ai {\&} law approaches to automating
  analysis and retrieval of electronically stored information in discovery
  proceedings,'' \emph{Artificial Intelligence and Law}, vol.~18, no.~4, pp.
  311--320, Dec 2010. [Online]. Available:
  \url{https://doi.org/10.1007/s10506-010-9098-4}
\BIBentrySTDinterwordspacing

\bibitem{Zanibbi2012}
\BIBentryALTinterwordspacing
R.~Zanibbi and D.~Blostein, ``Recognition and retrieval of mathematical
  expressions,'' \emph{International Journal on Document Analysis and
  Recognition}, vol.~15, no.~4, pp. 331--357, Dec 2012. [Online]. Available:
  \url{https://doi.org/10.1007/s10032-011-0174-4}
\BIBentrySTDinterwordspacing

\bibitem{pathan2012recognition}
I.~K. Pathan, A.~A. Ali, and R.~Ramteke, ``Recognition of offline handwritten
  isolated urdu character,'' \emph{Advances in Computational Research}, vol.~4,
  no.~1, 2012.

\bibitem{parvez2013offline}
M.~T. Parvez and S.~A. Mahmoud, ``Offline arabic handwritten text recognition:
  a survey,'' \emph{ACM Computing Surveys (CSUR)}, vol.~45, no.~2, p.~23, 2013.

\bibitem{connell2001template}
S.~D. Connell and A.~K. Jain, ``Template-based online character recognition,''
  \emph{Pattern Recognition}, vol.~34, no.~1, pp. 1--14, 2001.

\bibitem{Mori1992}
S.~Mori, C.~Suen, and K.~Yamamoto, ``{Historical review of OCR research and
  development},'' \emph{Proceedings of the IEEE}, vol.~80, no.~7, pp.
  1029--1058, 1992.

\bibitem{wilkinson1992first}
R.~A. Wilkinson, J.~Geist, S.~Janet, P.~J. Grother, C.~J. Burges, R.~Creecy,
  B.~Hammond, J.~J. Hull, N.~Larsen, T.~P. Vogl \emph{et~al.}, \emph{The first
  census optical character recognition system conference}.\hskip 1em plus 0.5em
  minus 0.4em\relax US Department of Commerce, National Institute of Standards
  and Technology, 1992, vol. 184.

\bibitem{Kovacs-V1995}
Z.~Kov{\'{a}}cs-V, ``{A novel architecture for high quality hand-printed
  character recognition},'' \emph{Pattern Recognition}, vol.~28, no.~11, pp.
  1685--1692, 1995.

\bibitem{wolf2002text}
C.~Wolf, J.-M. Jolion, and F.~Chassaing, ``Text localization, enhancement and
  binarization in multimedia documents,'' in \emph{Object recognition supported
  by user interaction for service robots}, vol.~2.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2002, pp. 1037--1040.

\bibitem{gatos2004adaptive}
B.~Gatos, I.~Pratikakis, and S.~J. Perantonis, ``An adaptive binarization
  technique for low quality historical documents,'' in \emph{International
  Workshop on Document Analysis Systems}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2004, pp. 102--113.

\bibitem{he2005comparison}
J.~He, Q.~Do, A.~C. Downton, and J.~Kim, ``A comparison of binarization methods
  for historical archive documents,'' in \emph{Eighth International Conference
  on Document Analysis and Recognition (ICDAR'05)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2005, pp. 538--542.

\bibitem{sari2002off}
T.~Sari, L.~Souici, and M.~Sellami, ``Off-line handwritten arabic character
  segmentation algorithm: Acsa,'' in \emph{Frontiers in Handwriting
  Recognition, 2002. Proceedings. Eighth International Workshop on}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2002, pp. 452--457.

\bibitem{Mitchell}
T.~M. Mitchell, \emph{Machine Learning}, 1st~ed.\hskip 1em plus 0.5em minus
  0.4em\relax New York, NY, USA: McGraw-Hill, Inc., 1997.

\bibitem{lorigo2006offline}
L.~M. Lorigo and V.~Govindaraju, ``Offline arabic handwriting recognition: a
  survey,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, vol.~28, no.~5, pp. 712--724, 2006.

\bibitem{Khan2019a}
R.~A. Khan, A.~Meyer, H.~Konik, and S.~Bouakaz, ``Saliency-based framework for
  facial expression recognition,'' \emph{Frontiers of Computer Science},
  vol.~13, no.~1, pp. 183--198, 2019.

\bibitem{DL}
Y.~LeCun, Y.~Bengio, and G.~Hinton, ``Deep learning,'' \emph{Nature}, pp.
  436--444, 2015.

\bibitem{66287}
T.~M. {Breuel}, A.~{Ul-Hasan}, M.~A. {Al-Azawi}, and F.~{Shafait},
  ``High-performance ocr for printed english and fraktur using lstm networks,''
  in \emph{2013 International Conference on Document Analysis and Recognition},
  Aug 2013, pp. 683--687.

\bibitem{kitchenham2010systematic}
B.~Kitchenham, R.~Pretorius, D.~Budgen, O.~P. Brereton, M.~Turner, M.~Niazi,
  and S.~Linkman, ``Systematic literature reviews in software engineering--a
  tertiary study,'' \emph{Information and Software Technology}, vol.~52, no.~8,
  pp. 792--805, 2010.

\bibitem{nidhra2013knowledge}
S.~Nidhra, M.~Yanamadala, W.~Afzal, and R.~Torkar, ``Knowledge transfer
  challenges and mitigation strategies in global software development—a
  systematic literature review and industrial validation,'' \emph{International
  journal of information management}, vol.~33, no.~2, pp. 333--355, 2013.

\bibitem{graves2009offline}
A.~Graves and J.~Schmidhuber, ``Offline handwriting recognition with
  multidimensional recurrent neural networks,'' in \emph{Advances in neural
  information processing systems}, 2009, pp. 545--552.

\bibitem{bhattacharya2009handwritten}
U.~Bhattacharya and B.~B. Chaudhuri, ``Handwritten numeral databases of indian
  scripts and multistage recognition of mixed numerals,'' \emph{IEEE
  transactions on pattern analysis and machine intelligence}, vol.~31, no.~3,
  pp. 444--457, 2009.

\bibitem{graves2009novel}
A.~Graves, M.~Liwicki, S.~Fern{\'a}ndez, R.~Bertolami, H.~Bunke, and
  J.~Schmidhuber, ``A novel connectionist system for unconstrained handwriting
  recognition,'' \emph{IEEE transactions on pattern analysis and machine
  intelligence}, vol.~31, no.~5, pp. 855--868, 2009.

\bibitem{plotz2009markov}
T.~Pl{\"o}tz and G.~A. Fink, ``Markov models for offline handwriting
  recognition: a survey,'' \emph{International Journal on Document Analysis and
  Recognition (IJDAR)}, vol.~12, no.~4, p. 269, 2009.

\bibitem{desai2010gujarati}
A.~A. Desai, ``Gujarati handwritten numeral optical character reorganization
  through neural network,'' \emph{Pattern recognition}, vol.~43, no.~7, pp.
  2582--2589, 2010.

\bibitem{vamvakas2010handwritten}
G.~Vamvakas, B.~Gatos, and S.~J. Perantonis, ``Handwritten character
  recognition through two-stage foreground sub-sampling,'' \emph{Pattern
  Recognition}, vol.~43, no.~8, pp. 2807--2816, 2010.

\bibitem{cirecsan2010deep}
D.~C. Cirecsan, U.~Meier, L.~M. Gambardella, and J.~Schmidhuber, ``Deep, big,
  simple neural nets for handwritten digit recognition,'' \emph{Neural
  computation}, vol.~22, no.~12, pp. 3207--3220, 2010.

\bibitem{pradeep2011diagonal}
J.~Pradeep, E.~Srinivasan, and S.~Himavathi, ``Diagonal based feature
  extraction for handwritten character recognition system using neural
  network,'' in \emph{Electronics Computer Technology (ICECT), 2011 3rd
  International Conference on}, vol.~4.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2011, pp. 364--368.

\bibitem{ciresan2011convolutional}
D.~C. Ciresan, U.~Meier, L.~M. Gambardella, and J.~Schmidhuber, ``Convolutional
  neural network committees for handwritten character classification,'' in
  \emph{Document Analysis and Recognition (ICDAR), 2011 International
  Conference on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2011, pp.
  1135--1139.

\bibitem{patil2011handwritten}
V.~Patil and S.~Shimpi, ``Handwritten english character recognition using
  neural network,'' \emph{Elixir Comput Sci Eng}, vol.~41, pp. 5587--5591,
  2011.

\bibitem{gregor2015draw}
K.~Gregor, I.~Danihelka, A.~Graves, D.~J. Rezende, and D.~Wierstra, ``Draw: A
  recurrent neural network for image generation,'' \emph{arXiv preprint
  arXiv:1502.04623}, 2015.

\bibitem{plamondon2000online}
R.~Plamondon and S.~N. Srihari, ``Online and off-line handwriting recognition:
  a comprehensive survey,'' \emph{IEEE Transactions on pattern analysis and
  machine intelligence}, vol.~22, no.~1, pp. 63--84, 2000.

\bibitem{arica2001overview}
N.~Arica and F.~T. Yarman-Vural, ``An overview of character recognition focused
  on off-line handwriting,'' \emph{IEEE Transactions on Systems, Man, and
  Cybernetics, Part C (Applications and Reviews)}, vol.~31, no.~2, pp.
  216--233, 2001.

\bibitem{pechwitz2002ifn}
M.~Pechwitz, S.~S. Maddouri, V.~M{\"a}rgner, N.~Ellouze, H.~Amiri
  \emph{et~al.}, ``Ifn/enit-database of handwritten arabic words,'' in
  \emph{Proc. of CIFED}, vol.~2.\hskip 1em plus 0.5em minus 0.4em\relax
  Citeseer, 2002, pp. 127--136.

\bibitem{khorsheed2002off}
M.~S. Khorsheed, ``Off-line arabic character recognition--a review,''
  \emph{Pattern analysis \& applications}, vol.~5, no.~1, pp. 31--45, 2002.

\bibitem{oh2002class}
I.-S. Oh and C.~Y. Suen, ``A class-modular feedforward neural network for
  handwriting recognition,'' \emph{pattern recognition}, vol.~35, no.~1, pp.
  229--244, 2002.

\bibitem{srihari2002individuality}
S.~N. Srihari, S.-H. Cha, H.~Arora, and S.~Lee, ``Individuality of
  handwriting,'' \emph{Journal of forensic science}, vol.~47, no.~4, pp. 1--17,
  2002.

\bibitem{pechwitz2003hmm}
M.~Pechwitz and V.~Maergner, ``Hmm based approach for handwritten arabic word
  recognition using the ifn/enit-database,'' in \emph{null}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2003, p. 890.

\bibitem{liu2003handwritten}
C.-L. Liu, K.~Nakashima, H.~Sako, and H.~Fujisawa, ``Handwritten digit
  recognition: benchmarking of state-of-the-art techniques,'' \emph{Pattern
  recognition}, vol.~36, no.~10, pp. 2271--2285, 2003.

\bibitem{pal2004indian}
U.~Pal and B.~Chaudhuri, ``Indian script character recognition: a survey,''
  \emph{pattern Recognition}, vol.~37, no.~9, pp. 1887--1899, 2004.

\bibitem{liu2004online}
C.-L. Liu, S.~Jaeger, and M.~Nakagawa, ``'online recognition of chinese
  characters: the state-of-the-art,'' \emph{IEEE transactions on pattern
  analysis and machine intelligence}, vol.~26, no.~2, pp. 198--213, 2004.

\bibitem{bai2005study}
Z.-L. Bai and Q.~Huo, ``A study on the use of 8-directional features for online
  handwritten chinese character recognition,'' in \emph{Document Analysis and
  Recognition, 2005. Proceedings. Eighth International Conference on}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2005, pp. 262--266.

\bibitem{sharma2006recognition}
N.~Sharma, U.~Pal, F.~Kimura, and S.~Pal, ``Recognition of off-line handwritten
  devnagari characters using quadratic classifier,'' in \emph{Computer Vision,
  Graphics and Image Processing}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2006, pp. 805--816.

\bibitem{graves2006connectionist}
A.~Graves, S.~Fern{\'a}ndez, F.~Gomez, and J.~Schmidhuber, ``Connectionist
  temporal classification: labelling unsegmented sequence data with recurrent
  neural networks,'' in \emph{Proceedings of the 23rd international conference
  on Machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax ACM, 2006, pp.
  369--376.

\bibitem{bulacu2007text}
M.~Bulacu, L.~Schomaker, and A.~Brink, ``Text-independent writer identification
  and verification on offline arabic handwriting,'' in \emph{icdar}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2007, pp. 769--773.

\bibitem{liwicki2007novel}
M.~Liwicki, A.~Graves, S.~Fern{\`a}ndez, H.~Bunke, and J.~Schmidhuber, ``A
  novel approach to on-line handwriting recognition based on bidirectional long
  short-term memory networks,'' in \emph{Proceedings of the 9th International
  Conference on Document Analysis and Recognition, ICDAR 2007}, 2007.

\bibitem{hanmandlu2007fuzzy}
M.~Hanmandlu and O.~R. Murthy, ``Fuzzy model based recognition of handwritten
  numerals,'' \emph{Pattern Recognition}, vol.~40, no.~6, pp. 1840--1854, 2007.

\bibitem{khosravi2007introducing}
H.~Khosravi and E.~Kabir, ``Introducing a very large dataset of handwritten
  farsi digits and a study on their varieties,'' \emph{Pattern recognition
  letters}, vol.~28, no.~10, pp. 1133--1141, 2007.

\bibitem{graves2008unconstrained}
A.~Graves, M.~Liwicki, H.~Bunke, J.~Schmidhuber, and S.~Fern{\'a}ndez,
  ``Unconstrained on-line handwriting recognition with recurrent neural
  networks,'' in \emph{Advances in neural information processing systems},
  2008, pp. 577--584.

\bibitem{yin2013icdar}
F.~Yin, Q.-F. Wang, X.-Y. Zhang, and C.-L. Liu, ``Icdar 2013 chinese
  handwriting recognition competition,'' in \emph{Document Analysis and
  Recognition (ICDAR), 2013 12th International Conference on}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2013, pp. 1464--1470.

\bibitem{zimmermann2002automatic}
M.~Zimmermann and H.~Bunke, ``Automatic segmentation of the iam off-line
  database for handwritten english text,'' in \emph{Pattern Recognition, 2002.
  Proceedings. 16th International Conference on}, vol.~4.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2002, pp. 35--39.

\bibitem{KHAN201961}
R.~A. Khan, A.~Crenn, A.~Meyer, and S.~Bouakaz, ``A novel database of
  children's spontaneous facial expressions {(LIRIS-CSE)},'' \emph{Image and
  Vision Computing}, vol. 83-84, pp. 61 -- 69, 2019.

\bibitem{NNBook}
S.~RAJASEKARAN and G.~V. PAI, \emph{NEURAL NETWORKS, FUZZY SYSTEMS AND
  EVOLUTIONARY ALGORITHMS : SYNTHESIS AND APPLICATIONS}.\hskip 1em plus 0.5em
  minus 0.4em\relax PHI Learning, 2017.

\bibitem{vithlani2015study}
P.~Vithlani and C.~Kumbharana, ``A study of optical character patterns
  identified by the different ocr algorithms,'' \emph{International Journal of
  Scientific and Research Publications}, vol.~5, no.~3, pp. 2250--3153, 2015.

\bibitem{485891}
A.~K. {Jain}, {Jianchang Mao}, and K.~M. {Mohiuddin}, ``Artificial neural
  networks: a tutorial,'' \emph{Computer}, vol.~29, no.~3, pp. 31--44, March
  1996.

\bibitem{nawaz2003approach}
S.~N. Nawaz, M.~Sarfraz, A.~Zidouri, and W.~G. Al-Khatib, ``An approach to
  offline arabic character recognition using neural networks,'' in
  \emph{Electronics, Circuits and Systems, 2003. ICECS 2003. Proceedings of the
  2003 10th IEEE International Conference on}, vol.~3.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2003, pp. 1328--1331.

\bibitem{srihari2007offline}
S.~N. Srihari, X.~Yang, and G.~R. Ball, ``Offline chinese handwriting
  recognition: an assessment of current technology,'' \emph{Frontiers of
  Computer Science in China}, vol.~1, no.~2, pp. 137--155, 2007.

\bibitem{pradeep2012neural}
J.~Pradeep, E.~Srinivasan, and S.~Himavathi, ``Neural network based recognition
  system integrating feature extraction and classification for english
  handwritten,'' \emph{International Journal of Engineering-Transactions B:
  Applications}, vol.~25, no.~2, p.~99, 2012.

\bibitem{singh2011feature}
P.~Singh and S.~Budhiraja, ``Feature extraction and classification techniques
  in ocr systems for handwritten gurmukhi script--a survey,''
  \emph{International Journal of Engineering Research and Applications
  (IJERA)}, vol.~1, no.~4, pp. 1736--1739, 2011.

\bibitem{RizHam}
H.~Sharif and R.~A. Khan, ``A novel framework for automatic detection of
  autism: A study on corpus callosum and intracranial brain volume,'' arXiv
  2019:1903.11323.

\bibitem{shamsher2007ocr}
I.~Shamsher, Z.~Ahmad, J.~K. Orakzai, and A.~Adnan, ``Ocr for printed urdu
  script using feed forward neural network,'' in \emph{Proceedings of World
  Academy of Science, Engineering and Technology}, vol.~23, 2007, pp. 172--175.

\bibitem{al2009handwriting}
R.~Al-Jawfi, ``Handwriting arabic character recognition lenet using neural
  network.'' \emph{Int. Arab J. Inf. Technol.}, vol.~6, no.~3, pp. 304--309,
  2009.

\bibitem{liu2009new}
C.-L. Liu and C.~Y. Suen, ``A new benchmark on the recognition of handwritten
  bangla and farsi numeral characters,'' \emph{Pattern Recognition}, vol.~42,
  no.~12, pp. 3287--3295, 2009.

\bibitem{liu2005classification}
C.-L. Liu and H.~Fujisawa, ``Classification and learning for character
  recognition: comparison of methods and remaining problems,'' in \emph{Int.
  Workshop on Neural Networks and Learning in Document Analysis and
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax Citeseer, 2005.

\bibitem{boufenar2018investigation}
C.~Boufenar, A.~Kerboua, and M.~Batouche, ``Investigation on deep learning for
  off-line handwritten arabic character recognition,'' \emph{Cognitive Systems
  Research}, vol.~50, pp. 180--195, 2018.

\bibitem{sokar2018generic}
G.~Sokar, E.~E. Hemayed, and M.~Rehan, ``A generic ocr using deep siamese
  convolution neural networks,'' in \emph{2018 IEEE 9th Annual Information
  Technology, Electronics and Mobile Communication Conference (IEMCON)}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1238--1244.

\bibitem{lin2018chinese}
D.~Lin, F.~Lin, Y.~Lv, F.~Cai, and D.~Cao, ``Chinese character captcha
  recognition and performance estimation via deep neural network,''
  \emph{Neurocomputing}, vol. 288, pp. 11--19, 2018.

\bibitem{yang2018recognition}
H.~Yang, L.~Jin, and J.~Sun, ``Recognition of chinese text in historical
  documents with page-level annotations,'' in \emph{2018 16th International
  Conference on Frontiers in Handwriting Recognition (ICFHR)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2018, pp. 199--204.

\bibitem{alizadehashraf2017persian}
B.~Alizadehashraf and S.~Roohi, ``Persian handwritten character recognition
  using convolutional neural network,'' in \emph{2017 10th Iranian Conference
  on Machine Vision and Image Processing (MVIP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2017, pp. 247--251.

\bibitem{ghasemi2018persian}
S.~Ghasemi and A.~H. Jadidinejad, ``Persian text classification via
  character-level convolutional neural networks,'' in \emph{2018 8th Conference
  of AI \& Robotics and 10th RoboCup Iranopen International Symposium
  (IRANOPEN)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1--6.

\bibitem{boukharouba2017novel}
A.~Boukharouba and A.~Bennia, ``Novel feature extraction technique for the
  recognition of handwritten digits,'' \emph{Applied Computing and
  Informatics}, vol.~13, no.~1, pp. 19--26, 2017.

\bibitem{verma2012survey}
R.~Verma and J.~Ali, ``A-survey of feature extraction and classification
  techniques in ocr systems,'' \emph{International Journal of Computer
  Applications \& Information Technology}, vol.~1, no.~3, pp. 1--3, 2012.

\bibitem{yang2005discrimination}
L.~Yang, C.~Y. Suen, T.~D. Bui, and P.~Zhang, ``Discrimination of similar
  handwritten numerals based on invariant curvature features,'' \emph{Pattern
  recognition}, vol.~38, no.~7, pp. 947--963, 2005.

\bibitem{yang2009linear}
J.~Yang, K.~Yu, Y.~Gong, T.~S. Huang \emph{et~al.}, ``Linear spatial pyramid
  matching using sparse coding for image classification.'' in \emph{CVPR},
  vol.~1, no.~2, 2009, p.~6.

\bibitem{KHAN20131159}
\BIBentryALTinterwordspacing
R.~A. Khan, A.~Meyer, H.~Konik, and S.~Bouakaz, ``Framework for reliable,
  real-time facial expression recognition for low resolution images,''
  \emph{Pattern Recognition Letters}, vol.~34, no.~10, pp. 1159 -- 1168, 2013.
  [Online]. Available:
  \url{http://www.sciencedirect.com/science/article/pii/S0167865513001268}
\BIBentrySTDinterwordspacing

\bibitem{haddoud2016combining}
M.~Haddoud, A.~Mokhtari, T.~Lecroq, and S.~Abdedda{\"\i}m, ``Combining
  supervised term-weighting metrics for svm text classification with extended
  term representation,'' \emph{Knowledge and Information Systems}, vol.~49,
  no.~3, pp. 909--931, 2016.

\bibitem{ning2016object}
J.~Ning, J.~Yang, S.~Jiang, L.~Zhang, and M.-H. Yang, ``Object tracking via
  dual linear structured svm and explicit feature map,'' in \emph{Proceedings
  of the IEEE conference on computer vision and pattern recognition}, 2016, pp.
  4266--4274.

\bibitem{tao2016robust}
Q.-Q. Tao, S.~Zhan, X.-H. Li, and T.~Kurihara, ``Robust face detection using
  local cnn and svm based on kernel combination,'' \emph{Neurocomputing}, vol.
  211, pp. 98--105, 2016.

\bibitem{akbari2018novel}
Y.~Akbari, M.~J. Jalili, J.~Sadri, K.~Nouri, I.~Siddiqi, and C.~Djeddi, ``A
  novel database for automatic processing of persian handwritten bank checks,''
  \emph{Pattern Recognition}, vol.~74, pp. 253--265, 2018.

\bibitem{chandio2018character}
A.~A. Chandio, M.~Pickering, and K.~Shafi, ``Character classification and
  recognition for urdu texts in natural scene images,'' in \emph{2018
  International Conference on Computing, Mathematics and Engineering
  Technologies (iCoMET)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018,
  pp. 1--6.

\bibitem{kumar2018improved}
M.~Kumar, S.~R. Jindal, M.~Jindal, and G.~S. Lehal, ``Improved recognition
  results of medieval handwritten gurmukhi manuscripts using boosting and
  bagging methodologies,'' \emph{Neural Processing Letters}, pp. 1--14, 2018.

\bibitem{alma2002recognition}
S.~Alma'adeed, C.~Higgens, and D.~Elliman, ``Recognition of off-line
  handwritten arabic words using hidden markov model approach,'' in
  \emph{Pattern Recognition, 2002. Proceedings. 16th International Conference
  on}, vol.~3.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2002, pp. 481--484.

\bibitem{alma2004off}
S.~Alma’adeed, C.~Higgins, and D.~Elliman, ``Off-line recognition of
  handwritten arabic words using multiple hidden markov models,'' in
  \emph{Research and Development in Intelligent Systems XX}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2004, pp. 33--40.

\bibitem{cheriet2008visual}
M.~Cheriet, ``Visual recognition of arabic handwriting: challenges and new
  directions,'' in \emph{Arabic and Chinese Handwriting Recognition}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2008, pp. 1--21.

\bibitem{pal2012handwriting}
U.~Pal, R.~Jayadevan, and N.~Sharma, ``Handwriting recognition in indian
  regional scripts: a survey of offline techniques,'' \emph{ACM Transactions on
  Asian Language Information Processing (TALIP)}, vol.~11, no.~1, p.~1, 2012.

\bibitem{sahu2013offline}
V.~L. Sahu and B.~Kubde, ``Offline handwritten character recognition techniques
  using neural network: A review,'' \emph{International journal of science and
  Research (IJSR)}, vol.~2, no.~1, pp. 87--94, 2013.

\bibitem{tiwari2012novel}
M.~E. Tiwari and M.~Shreevastava, ``A novel technique to read small and capital
  handwritten character,'' \emph{International Journal of Advanced Computer
  Research}, vol.~2, no.~2, 2012.

\bibitem{4376996}
S.~{Touj}, N.~E.~B. {Amara}, and H.~{Amiri}, ``Two approaches for arabic script
  recognition-based segmentation using the hough transform,'' in \emph{Ninth
  International Conference on Document Analysis and Recognition}, vol.~2, Sep.
  2007, pp. 654--658.

\bibitem{Li1995}
\BIBentryALTinterwordspacing
M.-J. Li and R.-W. Dai, ``A personal handwritten chinese character recognition
  algorithm based on the generalized hough transform,'' in \emph{Third
  International Conference on Document Analysis and Recognition}, ser. ICDAR
  '95.\hskip 1em plus 0.5em minus 0.4em\relax Washington, DC, USA: IEEE
  Computer Society, 1995, pp. 828--. [Online]. Available:
  \url{http://dl.acm.org/citation.cfm?id=839278.840308}
\BIBentrySTDinterwordspacing

\bibitem{chaudhuri2010some}
A.~Chaudhuri, ``Some experiments on optical character recognition systems for
  different languages using soft computing techniques,'' Technical Report,
  Birla Institute of Technology Mesra, Patna Campus, India, 2010. Google
  Scholar, Tech. Rep., 2010.

\bibitem{bookCCH}
J.~Iivarinen and A.~Visa, \emph{Intelligent Robots and Computer Vision XV:
  Algorithms, Techniques, Active Vision, and Materials Handling}.\hskip 1em
  plus 0.5em minus 0.4em\relax SPIE, 1996, ch. Shape recognition of irregular
  objects, pp. 25--32.

\bibitem{LIU2004265}
C.-L. Liu, K.~Nakashima, H.~Sako, and H.~Fujisawa, ``Handwritten digit
  recognition: investigation of normalization and feature extraction
  techniques,'' \emph{Pattern Recognition}, vol.~37, no.~2, pp. 265 -- 279,
  2004.

\bibitem{Marquesde2001}
\BIBentryALTinterwordspacing
J.~P. Marques~de S{\'a}, \emph{Structural Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax Berlin, Heidelberg: Springer Berlin Heidelberg, 2001,
  pp. 243--289. [Online]. Available:
  \url{https://doi.org/10.1007/978-3-642-56651-6_6}
\BIBentrySTDinterwordspacing

\bibitem{rohtua}
\BIBentryALTinterwordspacing
S.~Lavirotte and L.~Pottier, ``Mathematical formula recognition using graph
  grammar,'' Electronic Imaging: Document Recognition, 1998. [Online].
  Available: \url{https://doi.org/10.1117/12.304644}
\BIBentrySTDinterwordspacing

\bibitem{ALVARO201458}
\BIBentryALTinterwordspacing
F.~Álvaro, J.-A. Sánchez, and J.-M. Benedí, ``Recognition of on-line
  handwritten mathematical expressions using 2d stochastic context-free
  grammars and hidden markov models,'' \emph{Pattern Recognition Letters},
  vol.~35, pp. 58 -- 67, 2014. [Online]. Available:
  \url{http://www.sciencedirect.com/science/article/pii/S016786551200308X}
\BIBentrySTDinterwordspacing

\bibitem{994702}
S.~{Melnik}, H.~{Garcia-Molina}, and E.~{Rahm}, ``Similarity flooding: a
  versatile graph matching algorithm and its application to schema matching,''
  in \emph{International Conference on Data Engineering}, 2002, pp. 117--128.

\bibitem{Jeh:2002}
\BIBentryALTinterwordspacing
G.~Jeh and J.~Widom, ``Simrank: A measure of structural-context similarity,''
  in \emph{Proceedings of the Eighth ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining}, 2002, pp. 538--543. [Online].
  Available: \url{http://doi.acm.org/10.1145/775047.775126}
\BIBentrySTDinterwordspacing

\bibitem{ZAGER200886}
\BIBentryALTinterwordspacing
L.~A. Zager and G.~C. Verghese, ``Graph similarity scoring and matching,''
  \emph{Applied Mathematics Letters}, vol.~21, no.~1, pp. 86 -- 94, 2008.
  [Online]. Available:
  \url{http://www.sciencedirect.com/science/article/pii/S0893965907001012}
\BIBentrySTDinterwordspacing

\bibitem{Leicht2006}
E.~Leicht, P.~Holme, and M.~Newman, ``Vertex similarity in networks,''
  \emph{Phys. Rev.}, 2006.

\bibitem{8263187}
P.~{Sahare} and S.~B. {Dhok}, ``Multilingual character segmentation and
  recognition schemes for indian document images,'' \emph{IEEE Access}, vol.~6,
  pp. 10\,603--10\,617, 2018.

\bibitem{grammar}
M.~Flasi{\'{n}}ski, ``Graph grammar models in syntactic pattern recognition,''
  in \emph{Progress in Computer Recognition Systems}, R.~Burduk, M.~Kurzynski,
  and M.~Wozniak, Eds., 2019.

\bibitem{Chaudhuri2017}
A.~Chaudhuri, K.~Mandaviya, P.~Badelia, and S.~K. Ghosh, \emph{Optical
  Character Recognition Systems for Different Languages with Soft
  Computing}.\hskip 1em plus 0.5em minus 0.4em\relax Springer International
  Publishing, 2017, ch. Optical Character Recognition Systems, pp. 9--41.

\bibitem{hussain2015comprehensive}
R.~Hussain, A.~Raza, I.~Siddiqi, K.~Khurshid, and C.~Djeddi, ``A comprehensive
  survey of handwritten document benchmarks: structure, usage and evaluation,''
  \emph{EURASIP Journal on Image and Video Processing}, vol. 2015, no.~1,
  p.~46, 2015.

\bibitem{Khan2011b}
R.~A. {Khan}, .~{Dinet}, and H.~{Konik}, ``Visual attention: Effects of blur,''
  in \emph{IEEE International Conference on Image Processing}, 2011, pp.
  3289--3292.

\bibitem{hangarge2010offline}
M.~Hangarge and B.~Dhandra, ``Offline handwritten script identification in
  document images,'' \emph{Int. J. Comput. Appl}, vol.~4, no.~6, pp. 6--10,
  2010.

\bibitem{liu2002handwritten}
C.-L. Liu, K.~Nakashima, H.~Sako, and H.~Fujisawa, ``Handwritten digit
  recognition using state-of-the-art techniques,'' in \emph{Frontiers in
  Handwriting Recognition, 2002. Proceedings. Eighth International Workshop
  on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2002, pp. 320--325.

\bibitem{vamvakas2008hierarchical}
G.~Vamvakas, B.~Gatos, and S.~Perantonis, ``Hierarchical classification of
  handwritten characters based on novel structural features,'' in
  \emph{Eleventh International Conference on Frontiers in Handwriting
  Recognition (ICFHR’08), Montreal, Canada}, 2008, pp. 535--539.

\bibitem{babu2014handwritten}
U.~R. Babu, A.~K. Chintha, and Y.~Venkateswarlu, ``Handwritten digit
  recognition using structural, statistical features and k-nearest neighbor
  classifier,'' \emph{International Journal of Information Engineering and
  Electronic Business}, vol.~6, no.~1, p.~62, 2014.

\bibitem{ahmed2017ucom}
S.~B. Ahmed, S.~Naz, S.~Swati, M.~I. Razzak, A.~I. Umar, and A.~A. Khan, ``Ucom
  offline dataset-an urdu handwritten dataset generation.'' \emph{Int. Arab J.
  Inf. Technol.}, vol.~14, no.~2, pp. 239--245, 2017.

\bibitem{el2007ifn}
H.~El~Abed and V.~Margner, ``The ifn/enit-database-a tool to develop arabic
  handwriting recognition systems,'' in \emph{Signal Processing and Its
  Applications, 2007. ISSPA 2007. 9th International Symposium on}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2007, pp. 1--4.

\bibitem{margner2007arabic}
V.~Margner and H.~El~Abed, ``Arabic handwriting recognition competition,'' in
  \emph{Document Analysis and Recognition, 2007. ICDAR 2007. Ninth
  International Conference on}, vol.~2.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2007, pp. 1274--1278.

\bibitem{solimanpour2006standard}
F.~Solimanpour, J.~Sadri, and C.~Y. Suen, ``Standard databases for recognition
  of handwritten digits, numerical strings, legal amounts, letters and dates in
  farsi language,'' in \emph{Tenth International workshop on Frontiers in
  handwriting recognition}.\hskip 1em plus 0.5em minus 0.4em\relax Suvisoft,
  2006.

\bibitem{haghighi2009new}
P.~J. Haghighi, N.~Nobile, C.~L. He, and C.~Y. Suen, ``A new large-scale
  multi-purpose handwritten farsi database,'' in \emph{International Conference
  Image Analysis and Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2009, pp. 278--286.

\bibitem{zhang2009hcl2000}
H.~Zhang, J.~Guo, G.~Chen, and C.~Li, ``Hcl2000-a large-scale handwritten
  chinese character database for handwritten character recognition,'' in
  \emph{Document Analysis and Recognition, 2009. ICDAR'09. 10th International
  Conference on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2009, pp.
  286--290.

\bibitem{marti2002iam}
U.-V. Marti and H.~Bunke, ``The iam-database: an english sentence database for
  offline handwriting recognition,'' \emph{International Journal on Document
  Analysis and Recognition}, vol.~5, no.~1, pp. 39--46, 2002.

\bibitem{Danger}
C.~Moseley, Ed., \emph{Atlas of the World’s Languages in Danger}.\hskip 1em
  plus 0.5em minus 0.4em\relax UNESCO Publishing, 2010.

\bibitem{tian2016multilingual}
S.~Tian, U.~Bhattacharya, S.~Lu, B.~Su, Q.~Wang, X.~Wei, Y.~Lu, and C.~L. Tan,
  ``Multilingual scene character recognition with co-occurrence of histogram of
  oriented gradients,'' \emph{Pattern Recognition}, vol.~51, pp. 125--134,
  2016.

\bibitem{toselli2016hmm}
A.~H. Toselli, E.~Vidal, V.~Romero, and V.~Frinken, ``Hmm word graph based
  keyword spotting in handwritten document images,'' \emph{Information
  Sciences}, vol. 370, pp. 497--518, 2016.

\bibitem{deshmukh2009analysis}
S.~Deshmukh and L.~Ragha, ``Analysis of directional features-stroke and contour
  for handwritten character recognition,'' in \emph{Advance Computing
  Conference, 2009. IACC 2009. IEEE International}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2009, pp. 1114--1118.

\bibitem{ahlawat2017off}
S.~Ahlawat and R.~Rishi, ``Off-line handwritten numeral recognition using
  hybrid feature set--a comparative analysis,'' \emph{Procedia Computer
  Science}, vol. 122, pp. 1092--1099, 2017.

\bibitem{sharma2013performance}
P.~Sharma and R.~Singh, ``Performance of english character recognition with and
  without noise,'' \emph{International Journal of Computer Trends and
  Technology-volume4Issue3-2013}, 2013.

\bibitem{patel2011handwritten}
C.~I. Patel, R.~Patel, and P.~Patel, ``Handwritten character recognition using
  neural network,'' \emph{International Journal of Scientific \& Engineering
  Research}, vol.~2, no.~5, pp. 1--6, 2011.

\bibitem{zhang2007novel}
P.~Zhang, T.~D. Bui, and C.~Y. Suen, ``A novel cascade ensemble classifier
  system with a high recognition performance on handwritten digits,''
  \emph{Pattern Recognition}, vol.~40, no.~12, pp. 3415--3429, 2007.

\bibitem{saha2013optical}
S.~Saha, N.~Paul, S.~K. Das, and S.~Kundu, ``Optical character recognition
  using 40-point feature extraction and artificial neural network,''
  \emph{International Journal of Advanced Research in Computer Science and
  Software Engineering}, vol.~3, no.~4, 2013.

\bibitem{avadesh2018optical}
M.~Avadesh and N.~Goyal, ``Optical character recognition for sanskrit using
  convolution neural networks,'' in \emph{2018 13th IAPR International Workshop
  on Document Analysis Systems (DAS)}.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2018, pp. 447--452.

\bibitem{mozaffari2004recognition}
S.~Mozaffari, K.~Faez, and H.~R. Kanan, ``Recognition of isolated handwritten
  farsi/arabic alphanumeric using fractal codes,'' in \emph{IEEE Proceeding of
  Southwest Symposium on Image Analysis and Interpretation}, 2004, pp.
  104--108.

\bibitem{soltanzadeh2004recognition}
H.~Soltanzadeh and M.~Rahmati, ``Recognition of persian handwritten digits
  using image profiles of multiple orientations,'' \emph{Pattern Recognition
  Letters}, vol.~25, no.~14, pp. 1569--1576, 2004.

\bibitem{broumandnia2007fast}
A.~Broumandnia and J.~Shanbehzadeh, ``Fast zernike wavelet moments for farsi
  character recognition,'' \emph{Image and Vision Computing}, vol.~25, no.~5,
  pp. 717--726, 2007.

\bibitem{cch}
H.~Freeman and L.~Davis, ``A corner finding algorithm for chain-coded curves,''
  \emph{IEEE Transcations on computers}, 1977.

\bibitem{naz2014optical}
S.~Naz, K.~Hayat, M.~I. Razzak, M.~W. Anwar, S.~A. Madani, and S.~U. Khan,
  ``The optical character recognition of urdu-like cursive scripts,''
  \emph{Pattern Recognition}, vol.~47, no.~3, pp. 1229--1248, 2014.

\bibitem{javed2009improving}
S.~T. Javed and S.~Hussain, ``Improving nastalique specific pre-recognition
  process for urdu ocr,'' in \emph{Multitopic Conference, 2009. INMIC 2009.
  IEEE 13th International}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2009,
  pp. 1--6.

\bibitem{sagheer2009new}
M.~W. Sagheer, C.~L. He, N.~Nobile, and C.~Y. Suen, ``A new large urdu database
  for off-line handwriting recognition,'' in \emph{International Conference on
  Image Analysis and Processing}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2009, pp. 538--546.

\bibitem{raza2012unconstrained}
A.~Raza, I.~Siddiqi, A.~Abidi, and F.~Arif, ``An unconstrained benchmark urdu
  handwritten sentence database with automatic line segmentation,'' in
  \emph{Frontiers in Handwriting Recognition (ICFHR), 2012 International
  Conference on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2012, pp.
  491--496.

\bibitem{obaidullah2015numeral}
S.~M. Obaidullah, C.~Halder, N.~Das, and K.~Roy, ``Numeral script
  identification from handwritten document images,'' \emph{Procedia Computer
  Science}, vol.~54, pp. 585--594, 2015.

\bibitem{Daub}
I.~Daubechies, \emph{Ten Lectures on Wavelets}.\hskip 1em plus 0.5em minus
  0.4em\relax SIAM, 1992.

\bibitem{Asma}
N.~Asma and Z.~Kashif, ``Comparative analysis of raw images and meta feature
  based urdu {OCR} using {CNN} and {LSTM},'' \emph{International Journal of
  Advanced Computer Science and Applications}, 2018.

\bibitem{naseer2018comparative}
A.~Naseer and K.~Zafar, ``Comparative analysis of raw images and meta feature
  based urdu ocr using cnn and lstm,'' \emph{Int J Adv Comput Sci Appl},
  vol.~9, no.~1, pp. 419--424, 2018.

\bibitem{tayyab2018multi}
B.~U. Tayyab, M.~F. Naeem, A.~Ul-Hasan, F.~Shafait \emph{et~al.}, ``A
  multi-faceted ocr framework for artificial urdu news ticker text
  recognition,'' in \emph{2018 13th IAPR International Workshop on Document
  Analysis Systems (DAS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018,
  pp. 211--216.

\bibitem{fu2000user}
H.-C. Fu, H.-Y. Chang, Y.~Y. Xu, and H.-T. Pao, ``User adaptive handwriting
  recognition by self-growing probabilistic decision-based neural networks,''
  \emph{IEEE Transactions on neural networks}, vol.~11, no.~6, pp. 1373--1384,
  2000.

\bibitem{zhao2018multi}
Y.~Zhao, W.~Xue, and Q.~Li, ``A multi-scale crnn model for chinese papery
  medical document recognition,'' in \emph{2018 IEEE Fourth International
  Conference on Multimedia Big Data (BigMM)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2018, pp. 1--5.

\bibitem{luo2018multiple}
Y.~Luo, Y.~Li, S.~Huang, and F.~Han, ``Multiple chinese vehicle license plate
  localization in complex scenes,'' in \emph{2018 IEEE 3rd International
  Conference on Image, Vision and Computing (ICIVC)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2018, pp. 745--749.

\bibitem{mezghani2002line}
N.~Mezghani, A.~Mitiche, and M.~Cheriet, ``On-line recognition of handwritten
  arabic characters using a kohonen neural network,'' in \emph{Frontiers in
  Handwriting Recognition, 2002. Proceedings. Eighth International Workshop
  on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2002, pp. 490--495.

\bibitem{mozaffari2006comprehensive}
S.~Mozaffari, K.~Faez, F.~Faradji, M.~Ziaratban, and S.~M. Golzan, ``A
  comprehensive isolated farsi/arabic character database for handwritten ocr
  research,'' in \emph{Tenth International Workshop on Frontiers in Handwriting
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax Suvisoft, 2006.

\bibitem{mozaffari2009icdar}
S.~Mozaffari and H.~Soltanizadeh, ``Icdar 2009 handwritten farsi/arabic
  character recognition competition,'' in \emph{Document Analysis and
  Recognition, 2009. ICDAR'09. 10th International Conference on}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2009, pp. 1413--1417.

\bibitem{mezghani2012database}
A.~Mezghani, S.~Kanoun, M.~Khemakhem, and H.~El~Abed, ``A database for arabic
  handwritten text image recognition and writer identification,'' in
  \emph{Frontiers in Handwriting Recognition (ICFHR), 2012 International
  Conference on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2012, pp.
  399--402.

\bibitem{khayyat2014learning}
M.~Khayyat, L.~Lam, and C.~Y. Suen, ``Learning-based word spotting system for
  arabic handwritten documents,'' \emph{Pattern Recognition}, vol.~47, no.~3,
  pp. 1021--1030, 2014.

\bibitem{lutf2014arabic}
M.~Lutf, X.~You, Y.-m. Cheung, and C.~P. Chen, ``Arabic font recognition based
  on diacritics features,'' \emph{Pattern Recognition}, vol.~47, no.~2, pp.
  672--684, 2014.

\bibitem{elarian2015arabic}
Y.~Elarian, I.~Ahmad, S.~Awaida, W.~G. Al-Khatib, and A.~Zidouri, ``An arabic
  handwriting synthesis system,'' \emph{Pattern Recognition}, vol.~48, no.~3,
  pp. 849--861, 2015.

\bibitem{akram2016using}
H.~Akram, S.~Khalid \emph{et~al.}, ``Using features of local densities,
  statistics and hmm toolkit (htk) for offline arabic handwriting text
  recognition,'' \emph{Journal of Electrical Systems and Information
  Technology}, 2016.

\bibitem{elleuch2016new}
M.~Elleuch, R.~Maalej, and M.~Kherallah, ``A new design based-svm of the cnn
  classifier architecture with dropout for offline arabic handwritten
  recognition,'' \emph{Procedia Computer Science}, vol.~80, pp. 1712--1723,
  2016.

\bibitem{jebril2018recognition}
N.~A. Jebril, H.~R. Al-Zoubi, and Q.~A. Al-Haija, ``Recognition of handwritten
  arabic characters using histograms of oriented gradient (hog),''
  \emph{Pattern Recognition and Image Analysis}, vol.~28, no.~2, pp. 321--345,
  2018.

\bibitem{ICME_Khan}
R.~A. Khan, A.~Meyer, H.~Konik, and S.~Bouakaz, ``Pain detection through shape
  and appearance features,'' in \emph{IEEE International Conference on
  Multimedia and Expo (ICME)}, 2013.

\bibitem{rabby2018bornonet}
A.~S.~A. Rabby, S.~Haque, S.~Islam, S.~Abujar, and S.~A. Hossain, ``Bornonet:
  Bangla handwritten characters recognition using convolutional neural
  network,'' \emph{Procedia computer science}, vol. 143, pp. 528--535, 2018.

\bibitem{dutta2017towards}
K.~Dutta, P.~Krishnan, M.~Mathew, and C.~Jawahar, ``Towards accurate
  handwritten word recognition for hindi and bangla,'' in \emph{National
  Conference on Computer Vision, Pattern Recognition, Image Processing, and
  Graphics}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2017, pp.
  470--480.

\bibitem{sagar2008ocr}
B.~Sagar, G.~Shobha, and R.~Kumar, ``Ocr for printed kannada text to machine
  editable format using database approach,'' \emph{WSEAS Transactions on
  Computers}, vol.~7, no.~6, pp. 766--769, 2008.

\bibitem{lehal2000recognition}
G.~Lehal and N.~Bhatt, ``A recognition system for devnagri and english
  handwritten numerals,'' in \emph{Advances in Multimodal Interfaces—ICMI
  2000}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2000, pp. 442--449.

\bibitem{kimura1991handwritten}
F.~Kimura and M.~Shridhar, ``Handwritten numerical recognition based on
  multiple algorithms,'' \emph{Pattern recognition}, vol.~24, no.~10, pp.
  969--983, 1991.

\bibitem{patil2002neural}
S.~B. Patil and N.~Subbareddy, ``Neural network based system for script
  identification in indian documents,'' \emph{Sadhana}, vol.~27, no.~1, pp.
  83--97, 2002.

\bibitem{hanmandlu2007input}
M.~Hanmandlu, J.~Grover, V.~K. Madasu, and S.~Vasikarla, ``Input fuzzy modeling
  for the recognition of handwritten hindi numerals,'' in \emph{Information
  Technology, 2007. ITNG'07. Fourth International Conference on}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2007, pp. 208--213.

\bibitem{garg2010s}
G.~N. Kumar, K.~Lakhwinder, and J.~MK, ``Segmentation of handwritten hindi
  text,'' \emph{International Journal of Computer Applications (IJCA)}, 2010.

\bibitem{garg2010new}
Kumar, Lakhwinder, and MK, ``A new method for line segmentation of handwritten
  hindi text,'' in \emph{International Conference on Information Technology:
  New Generations (ITNG)}, 2010, pp. 392--397.

\bibitem{perwej2012machine}
Y.~Perwej and A.~Chaturvedi, ``Machine recognition of hand written characters
  using neural networks,'' \emph{arXiv preprint arXiv:1205.3964}, 2012.

\bibitem{naz2017urdu}
S.~Naz, A.~I. Umar, R.~Ahmad, I.~Siddiqi, S.~B. Ahmed, M.~I. Razzak, and
  F.~Shafait, ``Urdu nastaliq recognition using convolutional--recursive deep
  learning,'' \emph{Neurocomputing}, vol. 243, pp. 80--87, 2017.

\bibitem{al2018deep}
M.~Al-Ayyoub, A.~Nuseir, K.~Alsmearat, Y.~Jararweh, and B.~Gupta, ``Deep
  learning for arabic nlp: A survey,'' \emph{Journal of computational science},
  vol.~26, pp. 522--531, 2018.

\bibitem{suryani2016benefits}
D.~Suryani, P.~Doetsch, and H.~Ney, ``On the benefits of convolutional neural
  network combinations in offline handwriting recognition,'' in \emph{2016 15th
  International Conference on Frontiers in Handwriting Recognition
  (ICFHR)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 193--198.

\bibitem{wu2017improving}
Y.-C. Wu, F.~Yin, and C.-L. Liu, ``Improving handwritten chinese text
  recognition using neural network language models and convolutional neural
  network shape models,'' \emph{Pattern Recognition}, vol.~65, pp. 251--264,
  2017.

\bibitem{shi2017fisher}
C.~Shi, Y.~Wang, F.~Jia, K.~He, C.~Wang, and B.~Xiao, ``Fisher vector for scene
  character recognition: A comprehensive evaluation,'' \emph{Pattern
  Recognition}, vol.~72, pp. 1--14, 2017.

\bibitem{feng2017robust}
Z.~Feng, Z.~Yang, L.~Jin, S.~Huang, and J.~Sun, ``Robust shared feature
  learning for script and handwritten/machine-printed identification,''
  \emph{Pattern Recognition Letters}, vol. 100, pp. 6--13, 2017.

\bibitem{chaudhuri2017approach}
B.~B. Chaudhuri and C.~Adak, ``An approach for detecting and cleaning of
  struck-out handwritten text,'' \emph{Pattern Recognition}, vol.~61, pp.
  282--294, 2017.

\bibitem{zhang2015handwritten}
X.~Zhang and C.~L. Tan, ``Handwritten word image matching based on heat kernel
  signature,'' \emph{Pattern Recognition}, vol.~48, no.~11, pp. 3346--3356,
  2015.

\bibitem{su2017accurate}
B.~Su and S.~Lu, ``Accurate recognition of words in scenes without character
  segmentation using recurrent neural network,'' \emph{Pattern Recognition},
  vol.~63, pp. 397--405, 2017.

\bibitem{abdi2015model}
M.~N. Abdi and M.~Khemakhem, ``A model-based approach to offline
  text-independent arabic writer identification and verification,''
  \emph{Pattern Recognition}, vol.~48, no.~5, pp. 1890--1903, 2015.

\bibitem{yousfi2017contribution}
S.~Yousfi, S.-A. Berrani, and C.~Garcia, ``Contribution of recurrent
  connectionist language models in improving lstm-based arabic text recognition
  in videos,'' \emph{Pattern Recognition}, vol.~64, pp. 245--254, 2017.

\bibitem{elanwar2018making}
R.~Elanwar, W.~Qin, and M.~Betke, ``Making scanned arabic documents machine
  accessible using an ensemble of svm classifiers,'' \emph{International
  Journal on Document Analysis and Recognition (IJDAR)}, vol.~21, no. 1-2, pp.
  59--75, 2018.

\bibitem{radwan2018neural}
M.~A. Radwan, M.~I. Khalil, and H.~M. Abbas, ``Neural networks pipeline for
  offline machine printed arabic ocr,'' \emph{Neural Processing Letters},
  vol.~48, no.~2, pp. 769--787, 2018.

\bibitem{doush2018novel}
I.~A. Doush, F.~Alkhateeb, and A.~H. Gharaibeh, ``A novel arabic ocr
  post-processing using rule-based and word context techniques,''
  \emph{International Journal on Document Analysis and Recognition (IJDAR)},
  vol.~21, no. 1-2, pp. 77--89, 2018.

\bibitem{sarkhel2017multi}
R.~Sarkhel, N.~Das, A.~Das, M.~Kundu, and M.~Nasipuri, ``A multi-scale deep
  quad tree based feature extraction method for the recognition of isolated
  handwritten characters of popular indic scripts,'' \emph{Pattern
  Recognition}, vol.~71, pp. 78--93, 2017.

\bibitem{choudhury2018handwritten}
A.~Choudhury, H.~S. Rana, and T.~Bhowmik, ``Handwritten bengali numeral
  recognition using hog based feature extraction algorithm,'' in \emph{2018 5th
  International Conference on Signal Processing and Integrated Networks
  (SPIN)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 687--690.

\bibitem{sarvaramini2018persian}
F.~Sarvaramini, A.~Nasrollahzadeh, and M.~Soryani, ``Persian handwritten
  character recognition using convolutional neural network,'' in
  \emph{Electrical Engineering (ICEE), Iranian Conference on}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2018, pp. 1676--1680.

\bibitem{long2018}
S.~Long, X.~He, and C.~Yao, ``Scene text detection and recognition: The deep
  learning era,'' arxiv 2018.

\bibitem{ILSVRC15}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, A.~C. Berg, and L.~Fei-Fei, ``{ImageNet
  Large Scale Visual Recognition Challenge},'' \emph{International Journal of
  Computer Vision (IJCV)}, vol. 115, no.~3, pp. 211--252, 2015.

\bibitem{Krizhevsky1}
\BIBentryALTinterwordspacing
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' in \emph{Proceedings of the 25th
  International Conference on Neural Information Processing Systems - Volume
  1}, ser. NIPS'12.\hskip 1em plus 0.5em minus 0.4em\relax USA: Curran
  Associates Inc., 2012, pp. 1097--1105. [Online]. Available:
  \url{http://dl.acm.org/citation.cfm?id=2999134.2999257}
\BIBentrySTDinterwordspacing

\bibitem{7298594}
C.~{Szegedy}, {Wei Liu}, {Yangqing Jia}, P.~{Sermanet}, S.~{Reed},
  D.~{Anguelov}, D.~{Erhan}, V.~{Vanhoucke}, and A.~{Rabinovich}, ``Going
  deeper with convolutions,'' in \emph{2015 IEEE Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2015, pp. 1--9.

\bibitem{ResNet}
K.~{He}, X.~{Zhang}, S.~{Ren}, and J.~{Sun}, ``Deep residual learning for image
  recognition,'' in \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2016, pp. 770--778.

\bibitem{Yuan2019}
\BIBentryALTinterwordspacing
T.-L. Yuan, Z.~Zhu, K.~Xu, C.-J. Li, T.-J. Mu, and S.-M. Hu, ``A large chinese
  text dataset in the wild,'' \emph{Journal of Computer Science and
  Technology}, vol.~34, no.~3, pp. 509--521, 2019. [Online]. Available:
  \url{https://doi.org/10.1007/s11390-019-1923-y}
\BIBentrySTDinterwordspacing

\bibitem{2019arXiv190700945N}
N.~{Nayef}, Y.~{Patel}, M.~{Busta}, P.~{Nath Chowdhury}, D.~{Karatzas},
  W.~{Khlif}, J.~{Matas}, U.~{Pal}, J.-C. {Burie}, C.-l. {Liu}, and J.-M.
  {Ogier}, ``{ICDAR2019 Robust Reading Challenge on Multi-lingual Scene Text
  Detection and Recognition -- RRC-MLT-2019},'' \emph{arXiv e-prints}, 2019.

\bibitem{comm2008}
\BIBentryALTinterwordspacing
G.~D. Markman, D.~S. Siegel, and M.~Wright, ``Research and technology
  commercialization,'' \emph{Journal of Management Studies}, vol.~45, no.~8,
  pp. 1401--1423, 2008. [Online]. Available:
  \url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-6486.2008.00803.x}
\BIBentrySTDinterwordspacing

\end{thebibliography}




\appendix





\end{document}
